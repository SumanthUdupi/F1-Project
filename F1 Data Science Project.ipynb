{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 Data Science Project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science Learning Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Mathematics for Data Science\n",
    "   - Algebra: Linear equations, matrix operations.\n",
    "   - Calculus: Derivatives, optimization.\n",
    "   - Probability fundamentals: Basic probability, conditional probability.\n",
    "\n",
    "### 2. Statistics Basics\n",
    "   - Descriptive statistics: Mean, median, mode, standard deviation, variance.\n",
    "   - Probability distributions: Normal, binomial, Poisson.\n",
    "   - Inferential statistics: Sampling, estimation.\n",
    "\n",
    "### 3. Python Programming\n",
    "   - Data types and structures: Lists, tuples, dictionaries, sets.\n",
    "   - Control structures: Loops, conditionals.\n",
    "   - Functions and modules.\n",
    "   - Data science libraries: Pandas, Numpy, Matplotlib.\n",
    "\n",
    "### 4. Data Wrangling and Cleaning\n",
    "   - Handling missing values: Imputation, removal.\n",
    "   - Handling outliers: Detection and treatment.\n",
    "   - Data transformation: Scaling, normalization, encoding categorical variables.\n",
    "\n",
    "### 5. Exploratory Data Analysis (EDA)\n",
    "   - Summary statistics: Mean, median, skewness, kurtosis.\n",
    "   - Data visualization: Histogram, boxplot, pairplot.\n",
    "   - Feature relationships: Correlation analysis, scatter plots.\n",
    "\n",
    "### 6. Probability and Probability Distributions\n",
    "   - Basic probability: Rules of probability, Bayes' theorem.\n",
    "   - Probability distributions: Normal, binomial, Poisson, uniform distributions.\n",
    "   - Sampling methods: Random, stratified, cluster sampling.\n",
    "\n",
    "### 7. Hypothesis Testing\n",
    "   - Basics: Null and alternative hypotheses.\n",
    "   - p-values and confidence intervals.\n",
    "   - Types of tests: t-tests, chi-square tests, ANOVA.\n",
    "\n",
    "### 8. Data Visualization\n",
    "   - Basic plots: Histogram, scatter plot, line plot.\n",
    "   - Advanced visualizations: Heatmap, pairplot, violin plot.\n",
    "   - Interactive visualizations: Plotly, Dash, Tableau basics.\n",
    "\n",
    "### 9. Linear Regression\n",
    "   - Simple linear regression.\n",
    "   - Multiple linear regression.\n",
    "   - Evaluation metrics: Mean Absolute Error (MAE), Mean Squared Error (MSE), R-squared.\n",
    "\n",
    "### 10. Logistic Regression\n",
    "- Binary classification.\n",
    "- Sigmoid function and decision boundary.\n",
    "- Model interpretation and performance metrics.\n",
    "\n",
    "### 11. Decision Trees and Random Forests\n",
    "- Basics of decision trees: Splitting, pruning, information gain.\n",
    "- Random forests: Ensemble learning, bagging.\n",
    "- Hyperparameters for tuning: Max depth, min samples split.\n",
    "\n",
    "### 12. k-Nearest Neighbors (kNN)\n",
    "- Distance metrics: Euclidean, Manhattan.\n",
    "- Choosing k and model performance.\n",
    "- Applications: Classification, regression.\n",
    "\n",
    "### 13. Model Evaluation Metrics\n",
    "- Classification metrics: Accuracy, precision, recall, F1-score, ROC-AUC.\n",
    "- Regression metrics: MAE, MSE, RMSE.\n",
    "- Cross-validation techniques.\n",
    "\n",
    "### 14. Clustering Algorithms\n",
    "- K-means clustering: Choosing k, cluster evaluation.\n",
    "- Hierarchical clustering: Dendrograms, agglomerative and divisive methods.\n",
    "- Evaluation metrics: Silhouette score, Davies-Bouldin index.\n",
    "\n",
    "### 15. Dimensionality Reduction\n",
    "- Principal Component Analysis (PCA): Eigenvalues, eigenvectors.\n",
    "- t-SNE: Visualization of high-dimensional data.\n",
    "- Application of dimensionality reduction in preprocessing.\n",
    "\n",
    "### 16. Hyperparameter Tuning\n",
    "- Grid Search and Random Search.\n",
    "- Cross-validation: k-Fold, Leave-One-Out.\n",
    "- Tuning with libraries: Scikit-Learn’s GridSearchCV.\n",
    "\n",
    "### 17. Neural Networks\n",
    "- Basics of neural networks: Perceptron, activation functions.\n",
    "- Backpropagation and gradient descent.\n",
    "- Types of layers: Input, hidden, output.\n",
    "\n",
    "### 18. Deep Learning with CNNs and RNNs\n",
    "- Convolutional Neural Networks (CNNs): Convolutional layers, pooling.\n",
    "- Recurrent Neural Networks (RNNs): Sequence data, LSTM, GRU.\n",
    "- Applications: Image classification, natural language processing.\n",
    "\n",
    "### 19. Natural Language Processing (NLP)\n",
    "- Text preprocessing: Tokenization, stemming, lemmatization.\n",
    "- Vectorization methods: Bag-of-Words, TF-IDF.\n",
    "- Advanced NLP: Word embeddings, language models (BERT, GPT).\n",
    "\n",
    "### 20. Model Deployment and Monitoring\n",
    "- Model deployment: Flask, FastAPI, Docker.\n",
    "- Cloud platforms: AWS, GCP, Azure for model deployment.\n",
    "- Monitoring models: Performance tracking, retraining triggers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading of Data, Libraries and Table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of tables and columns.\n",
    "\n",
    "| Table                     | Columns                                                                                                                                                                        |\n",
    "|---------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **circuits_df**           | `circuitId`, `circuitRef`, `name`, `location`, `country`, `lat`, `lng`, `alt`, `url`                                                                                           |\n",
    "| **constructor_results_df** | `constructorResultsId`, `raceId`, `constructorId`, `points`, `status`                                                                                                          |\n",
    "| **constructor_standings_df** | `constructorStandingsId`, `raceId`, `constructorId`, `points`, `position`, `positionText`, `wins`                                                                        |\n",
    "| **lap_times_df**          | `raceId`, `driverId`, `lap`, `position`, `time`, `milliseconds`                                                                                                                |\n",
    "| **pit_stops_df**          | `raceId`, `driverId`, `stop`, `lap`, `time`, `duration`, `milliseconds`                                                                                                        |\n",
    "| **qualifying_df**         | `qualifyId`, `raceId`, `driverId`, `constructorId`, `number`, `position`, `q1`, `q2`, `q3`                                                                                     |\n",
    "| **results_df**            | `resultId`, `raceId`, `driverId`, `constructorId`, `number`, `grid`, `position`, `positionText`, `positionOrder`, `points`, `laps`, `time`, `milliseconds`, `fastestLap`, `rank`, `fastestLapTime`, `fastestLapSpeed`, `statusId` |\n",
    "| **seasons_df**            | `year`, `url`                                                                                                                                                                  |\n",
    "| **sprint_results_df**     | `resultId`, `raceId`, `driverId`, `constructorId`, `number`, `grid`, `position`, `positionText`, `positionOrder`, `points`, `laps`, `time`, `milliseconds`, `fastestLap`, `fastestLapTime`, `statusId` |\n",
    "| **status_df**             | `statusId`, `status`                                                                                                                                                           |\n",
    "| **drivers_df**            | `driverId`, `driverRef`, `number`, `code`, `forename`, `surname`, `dob`, `nationality`, `url`                                                                                  |\n",
    "| **races_df**              | `raceId`, `year`, `round`, `circuitId`, `name`, `date`, `time`, `url`, `fp1_date`, `fp1_time`, `fp2_date`, `fp2_time`, `fp3_date`, `fp3_time`, `quali_date`, `quali_time`, `sprint_date`, `sprint_time` |\n",
    "| **constructors_df**       | `constructorId`, `constructorRef`, `name`, `nationality`, `url`                                                                                                                |\n",
    "| **driver_standings_df**   | `driverStandingsId`, `raceId`, `driverId`, `points`, `position`, `positionText`, `wins`                                                                                        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Importing Libraries:**\n",
    "\n",
    "  -   **Pandas** (`import pandas as pd`):  \n",
    "  Pandas is like an advanced spreadsheet tool that allows us to load, manipulate, and analyze large sets of data quickly.\n",
    "\n",
    "  -   **Seaborn** (`import seaborn as sns`):  \n",
    "  Seaborn is a tool for making nice-looking charts and graphs. It builds on top of another tool (Matplotlib) to make visualizations prettier and easier to create.\n",
    "\n",
    "  -   **Matplotlib** (`import matplotlib.pyplot as plt` and `import matplotlib`):  \n",
    "  This is a library for creating plots and charts in Python. Think of it like drawing tools that help us visualize data.\n",
    "\n",
    "  -   **NumPy** (`import numpy as np`):  \n",
    "  NumPy is used for handling numbers and calculations in a more efficient way. It’s great for working with large groups of numbers, especially in math-heavy tasks.\n",
    "\n",
    "  -   **Scikit-Learn** (`from sklearn.model_selection import train_test_split`):  \n",
    "  This is a popular library for machine learning. It helps split data into training and testing parts, which is a key step in training predictive models.\n",
    "\n",
    "2. **Setting Up Warnings:**\n",
    "\n",
    "```python\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "```\n",
    "\n",
    "3. **Printing Version Information:**\n",
    "```python\n",
    "print(\"Pandas version:\", pd.__version__)\n",
    "print(\"Seaborn version:\", sns.__version__)\n",
    "print(\"Matplotlib version:\", matplotlib.__version__)\n",
    "print(\"NumPy version:\", np.__version__)\n",
    "\n",
    "These lines display the versions of each library in use, which helps in keeping track of the exact setup, since different versions might have small differences in functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(\"Pandas version:\", pd.__version__)\n",
    "print(\"Seaborn version:\", sns.__version__)\n",
    "print(\"Matplotlib version:\", matplotlib.__version__)\n",
    "print(\"NumPy version:\", np.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuits_df = pd.read_csv(r'C:\\Dataset\\F1 Data set\\circuits.csv')\n",
    "constructor_results_df = pd.read_csv(r'C:\\Dataset\\F1 Data set\\constructor_results.csv')\n",
    "constructor_standings_df = pd.read_csv(r'C:\\Dataset\\F1 Data set\\constructor_standings.csv')\n",
    "lap_times_df = pd.read_csv(r'C:\\Dataset\\F1 Data set\\lap_times.csv')\n",
    "pit_stops_df = pd.read_csv(r'C:\\Dataset\\F1 Data set\\pit_stops.csv')\n",
    "qualifying_df = pd.read_csv(r'C:\\Dataset\\F1 Data set\\qualifying.csv')\n",
    "results_df = pd.read_csv(r'C:\\Dataset\\F1 Data set\\results.csv')\n",
    "seasons_df = pd.read_csv(r'C:\\Dataset\\F1 Data set\\seasons.csv')\n",
    "sprint_results_df = pd.read_csv(r'C:\\Dataset\\F1 Data set\\sprint_results.csv')\n",
    "status_df = pd.read_csv(r'C:\\Dataset\\F1 Data set\\status.csv')\n",
    "drivers_df = pd.read_csv(r'C:\\Dataset\\F1 Data set\\drivers.csv')\n",
    "races_df = pd.read_csv(r'C:\\Dataset\\F1 Data set\\races.csv')\n",
    "constructors_df = pd.read_csv(r'C:\\Dataset\\F1 Data set\\constructors.csv')\n",
    "driver_standings_df = pd.read_csv(r'C:\\Dataset\\F1 Data set\\driver_standings.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Creating a Dictionary of DataFrames**:\n",
    "   - A dictionary called `dataframes` is created, where each key-value pair represents a table name and its corresponding DataFrame. This setup makes it easy to iterate over multiple tables.\n",
    "\n",
    "2. **Looping to Display Shapes and Sample Rows**:\n",
    "   - The first loop iterates over each DataFrame in the dictionary, printing:\n",
    "     - The name of the DataFrame.\n",
    "     - The shape of the DataFrame, which shows the number of rows and columns.\n",
    "     - The first few rows of data using `head()`, giving a sample preview of the data.\n",
    "\n",
    "3. **Looping to Display Column Names**:\n",
    "   - The second loop iterates over each DataFrame again to print:\n",
    "     - The name of each table.\n",
    "     - A list of the column names in each DataFrame.\n",
    "     - This part is helpful for understanding the structure of each table and identifying available fields for analysis or further processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of Data Frames and their corresponding names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataframes = {\n",
    "    'circuits_df': circuits_df,\n",
    "    'constructor_results_df': constructor_results_df,\n",
    "    'constructor_standings_df': constructor_standings_df,\n",
    "    'lap_times_df': lap_times_df,\n",
    "    'pit_stops_df': pit_stops_df,\n",
    "    'qualifying_df': qualifying_df,\n",
    "    'results_df': results_df,\n",
    "    'seasons_df': seasons_df,\n",
    "    'sprint_results_df': sprint_results_df,\n",
    "    'status_df': status_df,\n",
    "    'drivers_df': drivers_df,\n",
    "    'races_df': races_df,\n",
    "    'constructors_df': constructors_df,\n",
    "    'driver_standings_df': driver_standings_df,\n",
    "}\n",
    "for name, df in dataframes.items():\n",
    "    print(f\"{name}: shape {df.shape}\")\n",
    "    print(df.head(), \"\\n\")\n",
    "for table_name, df in dataframes.items():\n",
    "    print(f\"Table: {table_name}\")\n",
    "    print(\"Columns:\", list(df.columns))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Table Data Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective: Find out which country has the most and least circuits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_circuits = circuits_df.groupby('country').size().reset_index(name='circuit_count')\n",
    "top_circuits = top_circuits.sort_values(by='circuit_count', ascending=False)\n",
    "top_5_countries = top_circuits.head(5)\n",
    "bottom_5_countries = top_circuits.tail(5)\n",
    "print(top_5_countries)\n",
    "print(bottom_5_countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective: Find out Top 5 Most Successful Drivers and Top 5 Drivers Who Led the Most Laps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wins = results_df[results_df['positionOrder'] == 1].groupby('driverId').size().reset_index(name='wins')\n",
    "\n",
    "# Step 2: Calculate total laps led by each driver\n",
    "laps_led = lap_times_df.groupby('driverId').size().reset_index(name='laps_led')\n",
    "\n",
    "# Step 3: Merge both results to have wins and laps led in one DataFrame\n",
    "combined = pd.merge(wins, laps_led, on='driverId', how='outer').fillna(0)\n",
    "\n",
    "# Step 4: Get top 5 drivers by wins\n",
    "top_5_winners = combined.nlargest(5, 'wins')\n",
    "\n",
    "# Step 5: Get top 5 drivers by laps led\n",
    "top_5_laps_led = combined.nlargest(5, 'laps_led')\n",
    "\n",
    "# Assuming you have a drivers_df to get driver names\n",
    "driver_names = drivers_df.set_index('driverId')\n",
    "\n",
    "# Step 6: Prepare tables for display\n",
    "top_5_winners['Driver'] = top_5_winners['driverId'].map(driver_names['forename'] + ' ' + driver_names['surname'])\n",
    "top_5_laps_led['Driver'] = top_5_laps_led['driverId'].map(driver_names['forename'] + ' ' + driver_names['surname'])\n",
    "\n",
    "# Final tables\n",
    "print(\"Top 5 Most Successful Drivers (Wins):\")\n",
    "print(top_5_winners[['Driver', 'wins']].to_string(index=False))\n",
    "\n",
    "print(\"\\nTop 5 Drivers Who Led the Most Laps:\")\n",
    "print(top_5_laps_led[['Driver', 'laps_led']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_seasons = seasons_df['year'].nunique()\n",
    "ferrari_id = constructors_df[constructors_df['constructorRef'] == 'ferrari']['constructorId'].values[0]\n",
    "merged_df = pd.merge(constructor_results_df, races_df[['raceId', 'year']], on='raceId')\n",
    "ferrari_participation = merged_df[merged_df['constructorId'] == ferrari_id]\n",
    "ferrari_unique_years = ferrari_participation['year'].nunique()\n",
    "ferrari_years = ferrari_participation['year'].unique()\n",
    "all_years = seasons_df['year'].unique()\n",
    "missed_years = set(all_years) - set(ferrari_years)\n",
    "print(f\"Total Seasons: {total_seasons}\")\n",
    "print(f\"Ferrari Participated in {ferrari_unique_years} Seasons\")\n",
    "print(f\"Years Ferrari Did Not Participate: {sorted(missed_years)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Mathematics for Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algebra Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Filter and Analyze Circuit Locations**\n",
    "   - **Goal**: Identify all unique `location` and `country` pairs in the `circuits_df` table and create a table where each `country` has a count of `circuits` it contains.\n",
    "   - **Hint**: Use grouping to count occurrences and display results.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution: Analyzing Unique Location-Country Pairs and Circuit Counts\n",
    "\n",
    "This code looks at the `circuits_df` DataFrame to find unique locations and countries, as well as how many circuits each country has.\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. **Find Unique Location-Country Pairs**:\n",
    "   - The code gets unique combinations of `location` and `country` from the `circuits_df` DataFrame. This helps us see where circuits are located without duplicates.\n",
    "\n",
    "   ```python\n",
    "   unique_location_country_pairs = circuits_df[['location', 'country']].drop_duplicates()\n",
    "   ```\n",
    "2. **Print Unique Pairs**:\n",
    "    - It then prints these unique location-country pairs to show the different circuits.\n",
    "\n",
    "    ```python\n",
    "    print(\"Unique location-country pairs:\")\n",
    "    print(unique_location_country_pairs)\n",
    "    ```\n",
    "3. **Count Circuits per Country**:\n",
    "    - The code groups the data by country and counts the number of unique circuits in each country. This tells us how many circuits each country has.\n",
    "\n",
    "    ```python\n",
    "    country_circuit_count = circuits_df.groupby('country')['circuitId'].nunique().reset_index(name='circuit_count')\n",
    "    ```\n",
    "4. **Print Circuit Count**:\n",
    "    - Finally, it prints the count of circuits for each country.\n",
    "\n",
    "    ```python\n",
    "    print(\"Circuit count per country:\")\n",
    "    print(country_circuit_count)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_location_country_pairs = circuits_df[['location', 'country']].drop_duplicates()\n",
    "print(\"Unique location-country pairs:\")\n",
    "print(unique_location_country_pairs)\n",
    "country_circuit_count = circuits_df.groupby('country')['circuitId'].nunique().reset_index(name='circuit_count')\n",
    "print(\"Circuit count per country:\")\n",
    "print(country_circuit_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Matrix of Constructor Standings**\n",
    "   - **Goal**: Create a matrix showing the `position` of constructors across multiple `races`. Each row represents a `raceId` and each column represents a `constructorId` from the `constructor_standings_df` table.\n",
    "   - **Hint**: Use pivoting or matrix transformation functions to reshape data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution: Creating a Constructor Position Matrix\n",
    "\n",
    "This code builds a matrix showing the positions of constructors across multiple races. Each row represents a race (`raceId`), and each column represents a constructor (`name`).\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. **Merge Constructor Data**:\n",
    "   - The `constructor_standings_df` is merged with the `constructors_df` to replace `constructorId` with the constructor's name.\n",
    "   - This makes the data more understandable by using names instead of numeric IDs.\n",
    "\n",
    "   ```python\n",
    "   merged_df = constructor_standings_df.merge(\n",
    "       constructors_df[['constructorId', 'name']],\n",
    "       on='constructorId',\n",
    "       how='left'\n",
    "   )\n",
    "   \n",
    "2. **Create the Matrix**:\n",
    "\n",
    "- The data is pivoted into a matrix where:\n",
    "    - Rows (index) represent raceId (the race).\n",
    "    - Columns (columns) represent name (constructor name).\n",
    "    - Values (values) represent the position of each constructor in the respective race.\n",
    "    \n",
    "    ```python\n",
    "    constructor_position_matrix = merged_df.pivot(\n",
    "        index='raceId',  \n",
    "        columns='name',  \n",
    "        values='position'\n",
    "    )\n",
    "\n",
    "3. **Handle Missing Values**:\n",
    "\n",
    "- Missing positions (where a constructor did not participate in a race) are filled with `\"N/A\"` for clarity.\n",
    "\n",
    "    ```python\n",
    "   constructor_position_matrix.fillna(\"N/A\", inplace=True)\n",
    "\n",
    "4. **Print the Matrix**:\n",
    "The final matrix is printed to display the constructor positions across races.\n",
    "\n",
    "    ```python\n",
    "    print(\"Constructor Position Matrix (Rows: raceId, Columns: Constructor Name):\")\n",
    "    print(constructor_position_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = constructor_standings_df.merge(\n",
    "    constructors_df[['constructorId', 'name']],\n",
    "    on='constructorId',\n",
    "    how='left'\n",
    ")\n",
    "constructor_position_matrix = merged_df.pivot(\n",
    "    index='raceId',  \n",
    "    columns='name',  \n",
    "    values='position' \n",
    ")\n",
    "constructor_position_matrix.fillna(\"N/A\", inplace=True)\n",
    "print(\"Constructor Position Matrix (Rows: raceId, Columns: Constructor Name):\")\n",
    "print(constructor_position_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Sum of Points by Driver**\n",
    "   - **Goal**: Calculate the total `points` each driver has scored across all races using the `results_df` table.\n",
    "   - **Hint**: Group by `driverId` and use aggregation to sum the `points`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = results_df.merge(drivers_df[['driverId', 'forename', 'surname']], on='driverId', how='left')\n",
    "merged_df['driver_name'] = merged_df['forename'] + ' ' + merged_df['surname']\n",
    "total_driver_points = merged_df.groupby('driver_name')['points'].sum().reset_index()\n",
    "total_driver_points.rename(columns={'points': 'total_points'}, inplace=True)\n",
    "total_driver_points = total_driver_points.sort_values(by='total_points', ascending=False)\n",
    "print(\"Total Points Scored by Each Driver:\")\n",
    "print(total_driver_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Eigenvalues of a Points Matrix**\n",
    "   - **Goal**: Construct a 2x2 matrix of points scored by two constructors in two races from `constructor_results_df` and compute its eigenvalues.\n",
    "   - **Hint**: Choose two specific `constructorId`s and `raceId`s for simplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Solution: Analyzing Constructor Points and Eigenvalues\n",
    "\n",
    "This code calculates a matrix of points scored by two constructors in two races and computes the eigenvalues of that matrix. It uses the `constructor_results_df` DataFrame to derive the points.\n",
    "\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. **Group Data by Constructor and Race**:\n",
    "   - The data is grouped by `constructorId` and `raceId`, and the total points scored by each constructor in each race are calculated.\n",
    "\n",
    "  ```python\n",
    "selected_data = constructor_results_df.groupby(['constructorId', 'raceId'])['points'].sum().reset_index()\n",
    "\n",
    "2. **Select Two Constructors and Two Races**:\n",
    "  - Two constructors and two races are chosen for simplicity and analysis.\n",
    "\n",
    "  ```python\n",
    "constructors = selected_data['constructorId'].unique()[:2]\n",
    "races = selected_data['raceId'].unique()[:2]\n",
    "  \n",
    "3. **Construct the Points Matrix**:\n",
    "\n",
    "  - A 2x2 matrix is created where each cell contains the points scored by a specific constructor in a specific race. If no points are available for a combination, it is set to 0.\n",
    "\n",
    "  ```python\n",
    "  points_matrix = np.zeros((2, 2))\n",
    "  for i, constructor in enumerate(constructors):\n",
    "      for j, race in enumerate(races):\n",
    "          points = selected_data[\n",
    "              (selected_data['constructorId'] == constructor) & \n",
    "              (selected_data['raceId'] == race)\n",
    "          ]['points']\n",
    "          points_matrix[i, j] = points.values[0] if not points.empty else 0\n",
    "\n",
    "4. **Compute Eigenvalues**:\n",
    "\n",
    "  - The eigenvalues of the points matrix are calculated using NumPy's eigvals function. These eigenvalues provide mathematical insights into the matrix.\n",
    "  ```python\n",
    "  eigenvalues = np.linalg.eigvals(points_matrix)\n",
    "\n",
    "5. **Print the Results**:\n",
    "\n",
    "  - The constructed points matrix and its eigenvalues are displayed.\n",
    "  ```python\n",
    "  print(\"Points Matrix:\")\n",
    "  print(points_matrix)\n",
    "  print(\"\\nEigenvalues:\")\n",
    "  print(eigenvalues)\n",
    "\n",
    "### Explanation of the Output:\n",
    "\n",
    "#### **Points Matrix**:\n",
    "- The matrix represents the points scored by two constructors in two races.\n",
    "- Each row is a race, and each column is a constructor.\n",
    "- Example:\n",
    "  - Constructor 1 scored **0 points** in Race 1 and **1 point** in Race 2.\n",
    "  - Constructor 2 scored **0 points** in Race 1 and **4 points** in Race 2.\n",
    "\n",
    "#### **Eigenvalues**:\n",
    "- Eigenvalues summarize the matrix's characteristics.\n",
    "- For this matrix:\n",
    "  - **0** means there’s no contribution from Constructor 1 in Race 1.\n",
    "  - **4** reflects Constructor 2’s dominant score in Race 2.\n",
    "\n",
    "It helps quickly see which constructor performed better overall.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = constructor_results_df.groupby(['constructorId', 'raceId'])['points'].sum().reset_index()\n",
    "constructors = selected_data['constructorId'].unique()[:2]\n",
    "races = selected_data['raceId'].unique()[:2]\n",
    "points_matrix = np.zeros((2, 2))\n",
    "for i, constructor in enumerate(constructors):\n",
    "    for j, race in enumerate(races):\n",
    "        points = selected_data[(selected_data['constructorId'] == constructor) & (selected_data['raceId'] == race)]['points']\n",
    "        points_matrix[i, j] = points.values[0] if not points.empty else 0\n",
    "eigenvalues = np.linalg.eigvals(points_matrix)\n",
    "print(\"Points Matrix:\")\n",
    "print(points_matrix)\n",
    "print(\"\\nEigenvalues:\")\n",
    "print(eigenvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculus Exercises\n",
    "\n",
    "5. **Rate of Change in Lap Time**\n",
    "   - **Goal**: Given a `driverId`, calculate the rate of change of their `lap` times over successive laps in the `lap_times_df` table.\n",
    "   - **Hint**: Use `diff()` to compute time differences between laps for the same `driverId`.\n",
    "\n",
    "---\n",
    "\n",
    "6. **Total Pit Stop Duration Over Time**\n",
    "   - **Goal**: Calculate the total pit stop `duration` for a `driverId` over the course of a race, analyzing how pit stop duration changes across `laps` in `pit_stops_df`.\n",
    "   - **Hint**: Use the cumulative sum and analyze derivatives of cumulative times to find patterns.\n",
    "\n",
    "---\n",
    "\n",
    "7. **Optimization of Fastest Lap Speed**\n",
    "   - **Goal**: Identify the `fastestLapSpeed` from `results_df` for each `driverId` and find the lap where they achieved it to determine the race's optimal lap.\n",
    "   - **Hint**: Use `groupby()` and `max()` to isolate the fastest lap speeds.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Fundamentals Exercises\n",
    "\n",
    "8. **Probability of a Constructor Winning**\n",
    "   - **Goal**: Calculate the probability of a specific `constructorId` having the highest `position` (winning) across all races in the `results_df` table.\n",
    "   - **Hint**: Filter for the first position, count the occurrences, and divide by the total number of races.\n",
    "\n",
    "---\n",
    "\n",
    "9. **Conditional Probability of Qualifying Position**\n",
    "   - **Goal**: Calculate the probability that a `driverId` qualifies in the top 3 (`position` <= 3) given that they participated in qualifying, using data from `qualifying_df`.\n",
    "   - **Hint**: Calculate the proportion of `position` <= 3 among all qualifying entries for each driver.\n",
    "\n",
    "---\n",
    "\n",
    "10. **Joint Probability of Winning and Fastest Lap**\n",
    "      - **Goal**: Calculate the probability that a driver has both won (`position` = 1) and had the `fastestLap` in a race, using `results_df`.\n",
    "      - **Hint**: Find races where both conditions are true for a `driverId` and calculate the frequency relative to the total races."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
