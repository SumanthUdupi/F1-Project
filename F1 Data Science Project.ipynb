{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 Data Science Project\n",
    "---\n",
    "## Data Science Learning Path\n",
    "---\n",
    "### 1. Mathematics for Data Science\n",
    "   - Algebra: Linear equations, matrix operations.\n",
    "   - Calculus: Derivatives, optimization.\n",
    "   - Probability fundamentals: Basic probability, conditional probability.\n",
    "---\n",
    "### 2. Statistics Basics\n",
    "   - Descriptive statistics: Mean, median, mode, standard deviation, variance.\n",
    "   - Probability distributions: Normal, binomial, Poisson.\n",
    "   - Inferential statistics: Sampling, estimation.\n",
    "---\n",
    "### 3. Python Programming\n",
    "   - Data types and structures: Lists, tuples, dictionaries, sets.\n",
    "   - Control structures: Loops, conditionals.\n",
    "   - Functions and modules.\n",
    "   - Data science libraries: Pandas, Numpy, Matplotlib.\n",
    "---\n",
    "### 4. Data Wrangling and Cleaning\n",
    "   - Handling missing values: Imputation, removal.\n",
    "   - Handling outliers: Detection and treatment.\n",
    "   - Data transformation: Scaling, normalization, encoding categorical variables.\n",
    "---\n",
    "### 5. Exploratory Data Analysis (EDA)\n",
    "   - Summary statistics: Mean, median, skewness, kurtosis.\n",
    "   - Data visualization: Histogram, boxplot, pairplot.\n",
    "   - Feature relationships: Correlation analysis, scatter plots.\n",
    "---\n",
    "### 6. Probability and Probability Distributions\n",
    "   - Basic probability: Rules of probability, Bayes' theorem.\n",
    "   - Probability distributions: Normal, binomial, Poisson, uniform distributions.\n",
    "   - Sampling methods: Random, stratified, cluster sampling.\n",
    "---\n",
    "### 7. Hypothesis Testing\n",
    "   - Basics: Null and alternative hypotheses.\n",
    "   - p-values and confidence intervals.\n",
    "   - Types of tests: t-tests, chi-square tests, ANOVA.\n",
    "---\n",
    "### 8. Data Visualization\n",
    "   - Basic plots: Histogram, scatter plot, line plot.\n",
    "   - Advanced visualizations: Heatmap, pairplot, violin plot.\n",
    "   - Interactive visualizations: Plotly, Dash, Tableau basics.\n",
    "---\n",
    "### 9. Linear Regression\n",
    "   - Simple linear regression.\n",
    "   - Multiple linear regression.\n",
    "   - Evaluation metrics: Mean Absolute Error (MAE), Mean Squared Error (MSE), R-squared.\n",
    "---\n",
    "### 10. Logistic Regression\n",
    "- Binary classification.\n",
    "- Sigmoid function and decision boundary.\n",
    "- Model interpretation and performance metrics.\n",
    "---\n",
    "### 11. Decision Trees and Random Forests\n",
    "- Basics of decision trees: Splitting, pruning, information gain.\n",
    "- Random forests: Ensemble learning, bagging.\n",
    "- Hyperparameters for tuning: Max depth, min samples split.\n",
    "---\n",
    "### 12. k-Nearest Neighbors (kNN)\n",
    "- Distance metrics: Euclidean, Manhattan.\n",
    "- Choosing k and model performance.\n",
    "- Applications: Classification, regression.\n",
    "---\n",
    "### 13. Model Evaluation Metrics\n",
    "- Classification metrics: Accuracy, precision, recall, F1-score, ROC-AUC.\n",
    "- Regression metrics: MAE, MSE, RMSE.\n",
    "- Cross-validation techniques.\n",
    "---\n",
    "### 14. Clustering Algorithms\n",
    "- K-means clustering: Choosing k, cluster evaluation.\n",
    "- Hierarchical clustering: Dendrograms, agglomerative and divisive methods.\n",
    "- Evaluation metrics: Silhouette score, Davies-Bouldin index.\n",
    "---\n",
    "### 15. Dimensionality Reduction\n",
    "- Principal Component Analysis (PCA): Eigenvalues, eigenvectors.\n",
    "- t-SNE: Visualization of high-dimensional data.\n",
    "- Application of dimensionality reduction in preprocessing.\n",
    "---\n",
    "### 16. Hyperparameter Tuning\n",
    "- Grid Search and Random Search.\n",
    "- Cross-validation: k-Fold, Leave-One-Out.\n",
    "- Tuning with libraries: Scikit-Learn’s GridSearchCV.\n",
    "---\n",
    "### 17. Neural Networks\n",
    "- Basics of neural networks: Perceptron, activation functions.\n",
    "- Backpropagation and gradient descent.\n",
    "- Types of layers: Input, hidden, output.\n",
    "---\n",
    "### 18. Deep Learning with CNNs and RNNs\n",
    "- Convolutional Neural Networks (CNNs): Convolutional layers, pooling.\n",
    "- Recurrent Neural Networks (RNNs): Sequence data, LSTM, GRU.\n",
    "- Applications: Image classification, natural language processing.\n",
    "---\n",
    "### 19. Natural Language Processing (NLP)\n",
    "- Text preprocessing: Tokenization, stemming, lemmatization.\n",
    "- Vectorization methods: Bag-of-Words, TF-IDF.\n",
    "- Advanced NLP: Word embeddings, language models (BERT, GPT).\n",
    "---\n",
    "### 20. Model Deployment and Monitoring\n",
    "- Model deployment: Flask, FastAPI, Docker.\n",
    "- Cloud platforms: AWS, GCP, Azure for model deployment.\n",
    "- Monitoring models: Performance tracking, retraining triggers.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of Libraries.\n",
    "\n",
    "1. **Importing Libraries:**\n",
    "\n",
    "  -   **Pandas** (`import pandas as pd`):  \n",
    "  Pandas is like an advanced spreadsheet tool that allows us to load, manipulate, and analyze large sets of data quickly.\n",
    "\n",
    "  -   **Seaborn** (`import seaborn as sns`):  \n",
    "  Seaborn is a tool for making nice-looking charts and graphs. It builds on top of another tool (Matplotlib) to make visualizations prettier and easier to create.\n",
    "\n",
    "  -   **Matplotlib** (`import matplotlib.pyplot as plt` and `import matplotlib`):  \n",
    "  This is a library for creating plots and charts in Python. Think of it like drawing tools that help us visualize data.\n",
    "\n",
    "  -   **NumPy** (`import numpy as np`):  \n",
    "  NumPy is used for handling numbers and calculations in a more efficient way. It’s great for working with large groups of numbers, especially in math-heavy tasks.\n",
    "\n",
    "  -   **Scikit-Learn** (`from sklearn.model_selection import train_test_split`):  \n",
    "  This is a popular library for machine learning. It helps split data into training and testing parts, which is a key step in training predictive models.\n",
    "\n",
    "2. **Setting Up Warnings:**\n",
    "\n",
    "   ```python\n",
    "   import warnings\n",
    "   warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "3. **Printing Version Information:**\n",
    "\n",
    "   ```python\n",
    "   print(\"Pandas version:\", pd.__version__)\n",
    "   print(\"Seaborn version:\", sns.__version__)\n",
    "   print(\"Matplotlib version:\", matplotlib.__version__)\n",
    "   print(\"NumPy version:\", np.__version__)\n",
    "\n",
    "These lines display the versions of each library in use, which helps in keeping track of the exact setup, since different versions might have small differences in functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 2.2.3\n",
      "Seaborn version: 0.13.2\n",
      "Matplotlib version: 3.9.3\n",
      "NumPy version: 2.2.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(\"Pandas version:\", pd.__version__)\n",
    "print(\"Seaborn version:\", sns.__version__)\n",
    "print(\"Matplotlib version:\", matplotlib.__version__)\n",
    "print(\"NumPy version:\", np.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of Data.\n",
    "\n",
    "1. **Creating a Dictionary of DataFrames**:\n",
    "   - A dictionary called `dataframes` is created, where each key-value pair represents a table name and its corresponding DataFrame. This setup makes it easy to iterate over multiple tables.\n",
    "\n",
    "2. **Looping to Display Shapes and Sample Rows**:\n",
    "   - The first loop iterates over each DataFrame in the dictionary, printing:\n",
    "     - The name of the DataFrame.\n",
    "     - The shape of the DataFrame, which shows the number of rows and columns.\n",
    "     - The first few rows of data using `head()`, giving a sample preview of the data.\n",
    "\n",
    "3. **Looping to Display Column Names**:\n",
    "   - The second loop iterates over each DataFrame again to print:\n",
    "     - The name of each table.\n",
    "     - A list of the column names in each DataFrame.\n",
    "     - This part is helpful for understanding the structure of each table and identifying available fields for analysis or further processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\suman\\\\Desktop\\\\F1 Dataset\\\\circuits.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m circuits_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43msuman\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDesktop\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mF1 Dataset\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mcircuits.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m constructor_results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msuman\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mF1 Dataset\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mconstructor_results.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m constructor_standings_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msuman\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mF1 Dataset\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mconstructor_standings.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\suman\\\\Desktop\\\\F1 Dataset\\\\circuits.csv'"
     ]
    }
   ],
   "source": [
    "circuits_df = pd.read_csv(r'C:\\Users\\suman\\Desktop\\F1 Dataset\\circuits.csv')\n",
    "constructor_results_df = pd.read_csv(r'C:\\Users\\suman\\Desktop\\F1 Dataset\\constructor_results.csv')\n",
    "constructor_standings_df = pd.read_csv(r'C:\\Users\\suman\\Desktop\\F1 Dataset\\constructor_standings.csv')\n",
    "lap_times_df = pd.read_csv(r'C:\\Users\\suman\\Desktop\\F1 Dataset\\lap_times.csv')\n",
    "pit_stops_df = pd.read_csv(r'C:\\Users\\suman\\Desktop\\F1 Dataset\\pit_stops.csv')\n",
    "qualifying_df = pd.read_csv(r'C:\\Users\\suman\\Desktop\\F1 Dataset\\qualifying.csv')\n",
    "results_df = pd.read_csv(r'C:\\Users\\suman\\Desktop\\F1 Dataset\\results.csv')\n",
    "seasons_df = pd.read_csv(r'C:\\Users\\suman\\Desktop\\F1 Dataset\\seasons.csv')\n",
    "sprint_results_df = pd.read_csv(r'C:\\Users\\suman\\Desktop\\F1 Dataset\\sprint_results.csv')\n",
    "status_df = pd.read_csv(r'C:\\Users\\suman\\Desktop\\F1 Dataset\\status.csv')\n",
    "drivers_df = pd.read_csv(r'C:\\Users\\suman\\Desktop\\F1 Dataset\\drivers.csv')\n",
    "races_df = pd.read_csv(r'C:\\Users\\suman\\Desktop\\F1 Dataset\\races.csv')\n",
    "constructors_df = pd.read_csv(r'C:\\Users\\suman\\Desktop\\F1 Dataset\\constructors.csv')\n",
    "driver_standings_df = pd.read_csv(r'C:\\Users\\suman\\Desktop\\F1 Dataset\\driver_standings.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of tables and columns.\n",
    "\n",
    "| Table                     | Columns                                                                                                                                                                        |\n",
    "|---------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **circuits_df**           | `circuitId`, `circuitRef`, `name`, `location`, `country`, `lat`, `lng`, `alt`, `url`                                                                                           |\n",
    "| **constructor_results_df** | `constructorResultsId`, `raceId`, `constructorId`, `points`, `status`                                                                                                          |\n",
    "| **constructor_standings_df** | `constructorStandingsId`, `raceId`, `constructorId`, `points`, `position`, `positionText`, `wins`                                                                        |\n",
    "| **lap_times_df**          | `raceId`, `driverId`, `lap`, `position`, `time`, `milliseconds`                                                                                                                |\n",
    "| **pit_stops_df**          | `raceId`, `driverId`, `stop`, `lap`, `time`, `duration`, `milliseconds`                                                                                                        |\n",
    "| **qualifying_df**         | `qualifyId`, `raceId`, `driverId`, `constructorId`, `number`, `position`, `q1`, `q2`, `q3`                                                                                     |\n",
    "| **results_df**            | `resultId`, `raceId`, `driverId`, `constructorId`, `number`, `grid`, `position`, `positionText`, `positionOrder`, `points`, `laps`, `time`, `milliseconds`, `fastestLap`, `rank`, `fastestLapTime`, `fastestLapSpeed`, `statusId` |\n",
    "| **seasons_df**            | `year`, `url`                                                                                                                                                                  |\n",
    "| **sprint_results_df**     | `resultId`, `raceId`, `driverId`, `constructorId`, `number`, `grid`, `position`, `positionText`, `positionOrder`, `points`, `laps`, `time`, `milliseconds`, `fastestLap`, `fastestLapTime`, `statusId` |\n",
    "| **status_df**             | `statusId`, `status`                                                                                                                                                           |\n",
    "| **drivers_df**            | `driverId`, `driverRef`, `number`, `code`, `forename`, `surname`, `dob`, `nationality`, `url`                                                                                  |\n",
    "| **races_df**              | `raceId`, `year`, `round`, `circuitId`, `name`, `date`, `time`, `url`, `fp1_date`, `fp1_time`, `fp2_date`, `fp2_time`, `fp3_date`, `fp3_time`, `quali_date`, `quali_time`, `sprint_date`, `sprint_time` |\n",
    "| **constructors_df**       | `constructorId`, `constructorRef`, `name`, `nationality`, `url`                                                                                                                |\n",
    "| **driver_standings_df**   | `driverStandingsId`, `raceId`, `driverId`, `points`, `position`, `positionText`, `wins`                                                                                        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataframes = {\n",
    "    'circuits_df': circuits_df,\n",
    "    'constructor_results_df': constructor_results_df,\n",
    "    'constructor_standings_df': constructor_standings_df,\n",
    "    'lap_times_df': lap_times_df,\n",
    "    'pit_stops_df': pit_stops_df,\n",
    "    'qualifying_df': qualifying_df,\n",
    "    'results_df': results_df,\n",
    "    'seasons_df': seasons_df,\n",
    "    'sprint_results_df': sprint_results_df,\n",
    "    'status_df': status_df,\n",
    "    'drivers_df': drivers_df,\n",
    "    'races_df': races_df,\n",
    "    'constructors_df': constructors_df,\n",
    "    'driver_standings_df': driver_standings_df,\n",
    "}\n",
    "for name, df in dataframes.items():\n",
    "    print(f\"{name}: shape {df.shape}\")\n",
    "    print(df.head(), \"\\n\")\n",
    "for table_name, df in dataframes.items():\n",
    "    print(f\"Table: {table_name}\")\n",
    "    print(\"Columns:\", list(df.columns))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mathematics for Data Science\n",
    "\n",
    "### Algebra Exercises\n",
    "---\n",
    "1. **Filter and Analyze Circuit Locations.**\n",
    "   - **Goal**: Identify all unique `location` and `country` pairs in the `circuits_df` table and create a table where each `country` has a count of `circuits` it contains.\n",
    "   - **Hint**: Use grouping to count occurrences and display results.\n",
    "   \n",
    "   **_Solution :_** Analyzing Unique Location-Country Pairs and Circuit Counts\n",
    "\n",
    "      This code looks at the `circuits_df` DataFrame to find unique locations and countries, as well as how many circuits each country has.\n",
    "      \n",
    "   **_Steps :_**\n",
    "\n",
    "   1. **Find Unique Location-Country Pairs**:\n",
    "      - The code gets unique combinations of `location` and `country` from the `circuits_df` DataFrame. This helps us see where circuits are located without duplicates.\n",
    "\n",
    "      ```python\n",
    "      unique_location_country_pairs = circuits_df[['location', 'country']].drop_duplicates()\n",
    "      \n",
    "   2. **Print Unique Pairs**:\n",
    "      - It then prints these unique location-country pairs to show the different circuits.\n",
    "\n",
    "      ```python\n",
    "      print(\"Unique location-country pairs:\")\n",
    "      print(unique_location_country_pairs)\n",
    "      \n",
    "   3. **Count Circuits per Country**:\n",
    "      - The code groups the data by country and counts the number of unique circuits in each country. This tells us how many circuits each country has.\n",
    "\n",
    "      ```python\n",
    "      country_circuit_count = circuits_df.groupby('country')['circuitId'].nunique().reset_index(name='circuit_count')\n",
    "      \n",
    "   4. **Print Circuit Count**:\n",
    "      - Finally, it prints the count of circuits for each country.\n",
    "\n",
    "      ```python\n",
    "      print(\"Circuit count per country:\")\n",
    "      print(country_circuit_count)\n",
    "---      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_location_country_pairs = circuits_df[['location', 'country']].drop_duplicates()\n",
    "print(\"Unique location-country pairs:\")\n",
    "print(unique_location_country_pairs)\n",
    "country_circuit_count = circuits_df.groupby('country')['circuitId'].nunique().reset_index(name='circuit_count')\n",
    "print(\"Circuit count per country:\")\n",
    "print(country_circuit_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Matrix of Constructor Standings**\n",
    "   - **Goal**: Create a matrix showing the `position` of constructors across multiple `races`. Each row represents a `raceId` and each column represents a `constructorId` from the `constructor_standings_df` table.\n",
    "   - **Hint**: Use pivoting or matrix transformation functions to reshape data.\n",
    "\n",
    "   **_Solution:_** Creating a Constructor Position Matrix\n",
    "\n",
    "      This code builds a matrix showing the positions of constructors across multiple races. Each row represents a race (`raceId`), and each column represents a constructor (`name`).\n",
    "\n",
    "   **_Steps :_**\n",
    "\n",
    "   1. **Merge Constructor Data**:\n",
    "      - The `constructor_standings_df` is merged with the `constructors_df` to replace `constructorId` with the constructor's name.\n",
    "      - This makes the data more understandable by using names instead of numeric IDs.\n",
    "\n",
    "      ```python\n",
    "      merged_df = constructor_standings_df.merge(\n",
    "         constructors_df[['constructorId', 'name']],\n",
    "         on='constructorId',\n",
    "         how='left'\n",
    "      )\n",
    "      \n",
    "   2. **Create the Matrix**:\n",
    "\n",
    "   - The data is pivoted into a matrix where:\n",
    "      - Rows (index) represent raceId (the race).\n",
    "      - Columns (columns) represent name (constructor name).\n",
    "      - Values (values) represent the position of each constructor in the respective race.\n",
    "      \n",
    "      ```python\n",
    "      constructor_position_matrix = merged_df.pivot(\n",
    "         index='raceId',  \n",
    "         columns='name',  \n",
    "         values='position'\n",
    "      )\n",
    "\n",
    "   3. **Handle Missing Values**:\n",
    "\n",
    "   - Missing positions (where a constructor did not participate in a race) are filled with `\"N/A\"` for clarity.\n",
    "\n",
    "      ```python\n",
    "      constructor_position_matrix.fillna(\"N/A\", inplace=True)\n",
    "\n",
    "   4. **Print the Matrix**:\n",
    "   The final matrix is printed to display the constructor positions across races.\n",
    "\n",
    "      ```python\n",
    "      print(\"Constructor Position Matrix (Rows: raceId, Columns: Constructor Name):\")\n",
    "      print(constructor_position_matrix)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = constructor_standings_df.merge(\n",
    "    constructors_df[['constructorId', 'name']],\n",
    "    on='constructorId',\n",
    "    how='left'\n",
    ")\n",
    "constructor_position_matrix = merged_df.pivot(\n",
    "    index='raceId',  \n",
    "    columns='name',  \n",
    "    values='position' \n",
    ")\n",
    "constructor_position_matrix.fillna(\"N/A\", inplace=True)\n",
    "print(\"Constructor Position Matrix (Rows: raceId, Columns: Constructor Name):\")\n",
    "print(constructor_position_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Sum of Points by Driver**\n",
    "   - **Goal**: Calculate the total `points` each driver has scored across all races using the `results_df` table.\n",
    "   - **Hint**: Group by `driverId` and use aggregation to sum the `points`.\n",
    "\n",
    "   **_Solution:_** Summing Points Scored by Each Driver\n",
    "\n",
    "      **_Steps :_**\n",
    "\n",
    "   1. **Merge Driver Details with Results**\n",
    "      ```python\n",
    "      merged_df = results_df.merge(drivers_df[['driverId', 'forename', 'surname']], on='driverId', how='left')\n",
    "      ```\n",
    "      - **Purpose:** Combine race results (`results_df`) with driver details (`drivers_df`) to include the driver's first and last names alongside race data.\n",
    "      - **Key Points:**\n",
    "      - `on='driverId'`: The `driverId` column is used as the key for merging the two datasets.\n",
    "      - `how='left'`: Ensures all rows from `results_df` are retained, even if a matching driver isn't found in `drivers_df`. Missing names will appear as `NaN`.\n",
    "\n",
    "   2. **Create a Full Driver Name**\n",
    "      ```python\n",
    "      merged_df['driver_name'] = merged_df['forename'] + ' ' + merged_df['surname']\n",
    "      ```\n",
    "      - **Purpose:** Combine the `forename` and `surname` columns into a single column, `driver_name`, for easier readability and grouping.\n",
    "      - **Result:** A new column, `driver_name`, is added to `merged_df`, containing the full name of each driver.\n",
    "\n",
    "   3. **Calculate Total Points by Driver**\n",
    "      ```python\n",
    "      total_driver_points = merged_df.groupby('driver_name')['points'].sum().reset_index()\n",
    "      ```\n",
    "      - **Purpose:** Group the dataset by `driver_name` and calculate the total points scored by each driver across all races.\n",
    "      - **Steps:**\n",
    "      - `groupby('driver_name')`: Groups rows by each driver's name.\n",
    "      - `['points'].sum()`: Sums the `points` column for each group (driver).\n",
    "      - `reset_index()`: Converts the grouped result back into a DataFrame for easier manipulation.\n",
    "\n",
    "   4. **Rename the Points Column**\n",
    "      ```python\n",
    "      total_driver_points.rename(columns={'points': 'total_points'}, inplace=True)\n",
    "      ```\n",
    "      - **Purpose:** Rename the `points` column in `total_driver_points` to `total_points` for clarity.\n",
    "      - **Key Argument:**\n",
    "      - `inplace=True`: Ensures the renaming happens directly on the `total_driver_points` DataFrame.\n",
    "\n",
    "   5. **Sort Drivers by Total Points**\n",
    "      ```python\n",
    "      total_driver_points = total_driver_points.sort_values(by='total_points', ascending=False)\n",
    "      ```\n",
    "      - **Purpose:** Sort the drivers in descending order of their total points.\n",
    "      - **Key Points:**\n",
    "      - `by='total_points'`: Specifies the column used for sorting.\n",
    "      - `ascending=False`: Ensures the drivers with the highest points appear first.\n",
    "\n",
    "   6. **Display the Results**\n",
    "      ```python\n",
    "      print(\"Total Points Scored by Each Driver:\")\n",
    "      print(total_driver_points)\n",
    "      ```\n",
    "      - **Purpose:** Print the final `total_driver_points` DataFrame, showing each driver's name and their total points in descending order.\n",
    "\n",
    "   ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = results_df.merge(drivers_df[['driverId', 'forename', 'surname']], on='driverId', how='left')\n",
    "merged_df['driver_name'] = merged_df['forename'] + ' ' + merged_df['surname']\n",
    "total_driver_points = merged_df.groupby('driver_name')['points'].sum().reset_index()\n",
    "total_driver_points.rename(columns={'points': 'total_points'}, inplace=True)\n",
    "total_driver_points = total_driver_points.sort_values(by='total_points', ascending=False)\n",
    "print(\"Total Points Scored by Each Driver:\")\n",
    "print(total_driver_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Eigenvalues of a Points Matrix**\n",
    "   - **Goal**: Construct a 2x2 matrix of points scored by two constructors in two races from `constructor_results_df` and compute its eigenvalues.\n",
    "   - **Hint**: Choose two specific `constructorId`s and `raceId`s for simplicity.\n",
    "\n",
    "**_Solution:_** Analyzing Constructor Points and Eigenvalues\n",
    "\n",
    "This code calculates a matrix of points scored by two constructors in two races and computes the eigenvalues of that matrix. It uses the `constructor_results_df` DataFrame to derive the points.\n",
    "\n",
    "**_Steps:_**\n",
    "\n",
    "   1. **Group Data by Constructor and Race**:\n",
    "   - The data is grouped by `constructorId` and `raceId`, and the total points scored by each constructor in each race are calculated.\n",
    "\n",
    "      ```python\n",
    "      selected_data = constructor_results_df.groupby(['constructorId', 'raceId'])['points'].sum().reset_index()\n",
    "\n",
    "   2. **Select Two Constructors and Two Races**:\n",
    "   - Two constructors and two races are chosen for simplicity and analysis.\n",
    "\n",
    "      ```python\n",
    "      constructors = selected_data['constructorId'].unique()[:2]\n",
    "      races = selected_data['raceId'].unique()[:2]\n",
    "   \n",
    "   3. **Construct the Points Matrix**:\n",
    "\n",
    "   - A 2x2 matrix is created where each cell contains the points scored by a specific constructor in a specific race. If no points are available for a combination, it is set to 0.\n",
    "\n",
    "      ```python\n",
    "         points_matrix = np.zeros((2, 2))\n",
    "         for i, constructor in enumerate(constructors):\n",
    "            for j, race in enumerate(races):\n",
    "               points = selected_data[\n",
    "                     (selected_data['constructorId'] == constructor) & \n",
    "                     (selected_data['raceId'] == race)\n",
    "               ]['points']\n",
    "               points_matrix[i, j] = points.values[0] if not points.empty else 0\n",
    "\n",
    "   4. **Compute Eigenvalues**:\n",
    "\n",
    "   - The eigenvalues of the points matrix are calculated using NumPy's eigvals function. These eigenvalues provide mathematical insights into the matrix.\n",
    "         \n",
    "      ```python\n",
    "         eigenvalues = np.linalg.eigvals(points_matrix)\n",
    "\n",
    "   5. **Print the Results**:\n",
    "\n",
    "   - The constructed points matrix and its eigenvalues are displayed.\n",
    "   \n",
    "      ```python\n",
    "         print(\"Points Matrix:\")\n",
    "         print(points_matrix)\n",
    "         print(\"\\nEigenvalues:\")\n",
    "         print(eigenvalues)\n",
    "\n",
    "**_Explanation of the Output:_**\n",
    "   \n",
    "   **Points Matrix**:\n",
    "   - The matrix represents the points scored by two constructors in two races.\n",
    "   - Each row is a race, and each column is a constructor.\n",
    "   - Example:\n",
    "   - Constructor 1 scored **0 points** in Race 1 and **1 point** in Race 2.\n",
    "   - Constructor 2 scored **0 points** in Race 1 and **4 points** in Race 2.\n",
    "\n",
    "   **Eigenvalues**:\n",
    "   - Eigenvalues summarize the matrix's characteristics.\n",
    "   - For this matrix:\n",
    "   - **0** means there’s no contribution from Constructor 1 in Race 1.\n",
    "   - **4** reflects Constructor 2’s dominant score in Race 2.\n",
    "\n",
    "   It helps quickly see which constructor performed better overall.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = constructor_results_df.groupby(['constructorId', 'raceId'])['points'].sum().reset_index()\n",
    "constructors = selected_data['constructorId'].unique()[:2]\n",
    "races = selected_data['raceId'].unique()[:2]\n",
    "points_matrix = np.zeros((2, 2))\n",
    "for i, constructor in enumerate(constructors):\n",
    "    for j, race in enumerate(races):\n",
    "        points = selected_data[(selected_data['constructorId'] == constructor) & (selected_data['raceId'] == race)]['points']\n",
    "        points_matrix[i, j] = points.values[0] if not points.empty else 0\n",
    "eigenvalues = np.linalg.eigvals(points_matrix)\n",
    "print(\"Points Matrix:\")\n",
    "print(points_matrix)\n",
    "print(\"\\nEigenvalues:\")\n",
    "print(eigenvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculus Exercises\n",
    "\n",
    "5. **Rate of Change in Lap Time**\n",
    "\n",
    "   - **Goal**: Determine the rate of change in lap times for a given `driverId` by analyzing successive lap times in the `lap_times_df` table.\n",
    "\n",
    "   - **Hint**\n",
    "      - Use `sort_values()` to order the data by `driverId` and `lap` for proper calculation.\n",
    "      - Use `diff()` to compute the time difference between consecutive laps within each driver's lap records.\n",
    "\n",
    "**_Solution:_** Calculating Lap Time Change for Each Driver\n",
    "\n",
    "**_Steps:_**\n",
    "\n",
    "1. **Sort Lap Time Data**\n",
    "   ```python\n",
    "   lap_times_df = lap_times_df.sort_values(by=['driverId', 'lap'])\n",
    "   ```\n",
    "   - **Purpose:** Ensure the data is ordered by `driverId` and `lap` so that successive laps are properly aligned for computation.\n",
    "   - **Key Points:**\n",
    "     - Sorting is crucial for the `diff()` function to work as intended.\n",
    "     - `by=['driverId', 'lap']`: Sorts data first by `driverId` and then by `lap` number.\n",
    "\n",
    "2. **Calculate Rate of Change in Lap Times**\n",
    "   ```python\n",
    "   lap_times_df['lap_time_change'] = lap_times_df.groupby('driverId')['milliseconds'].diff()\n",
    "   ```\n",
    "   - **Purpose:** Compute the difference in lap times (`milliseconds`) for consecutive laps within each `driverId`.\n",
    "   - **Steps:**\n",
    "     - `groupby('driverId')`: Groups data by `driverId` so each driver's laps are processed independently.\n",
    "     - `['milliseconds'].diff()`: Calculates the difference in lap times between consecutive laps.\n",
    "   - **Result:** A new column, `lap_time_change`, is added to the DataFrame, indicating the change in lap time for each driver.\n",
    "\n",
    "3. **Display Relevant Data**\n",
    "   ```python\n",
    "   print(\"Rate of change of lap times for each driver:\")\n",
    "   print(lap_times_df[['driverId', 'lap', 'milliseconds', 'lap_time_change']].tail())\n",
    "   ```\n",
    "   - **Purpose:** Display the relevant columns to understand the lap time changes for each driver.\n",
    "   - **Key Points:**\n",
    "     - `[['driverId', 'lap', 'milliseconds', 'lap_time_change']]`: Selects only the necessary columns for display.\n",
    "     - `.tail()`: Shows the last few rows of the DataFrame to verify results.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lap_times_df = lap_times_df.sort_values(by=['driverId', 'lap'])\n",
    "lap_times_df['lap_time_change'] = lap_times_df.groupby('driverId')['milliseconds'].diff()\n",
    "print(\"Rate of change of lap times for each driver:\")\n",
    "print(lap_times_df[['driverId', 'lap', 'milliseconds', 'lap_time_change']].tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Total Pit Stop Duration Over Time**\n",
    "\n",
    "   - **Goal**: Calculate the total pit stop `duration` for a `driverId` over the course of a race, analyzing how pit stop duration changes across `laps` in `pit_stops_df`.\n",
    "\n",
    "   - **Hint**: Use the cumulative sum and analyze derivatives of cumulative times to find patterns.\n",
    "\n",
    "**_Solution:_** Calculating Total Pit Stop Duration and Changes Across Laps\n",
    "\n",
    "**_Steps:_**\n",
    "\n",
    "1. **Convert Duration to Numeric Values**\n",
    "   ```python\n",
    "   pit_stops_df['duration'] = pd.to_numeric(pit_stops_df['duration'], errors='coerce')\n",
    "   ```\n",
    "   - **Purpose:** Ensure the `duration` column is in a numeric format to perform arithmetic operations.\n",
    "   - **Key Points:**\n",
    "     - `pd.to_numeric()`: Converts `duration` to a numeric data type. If any value cannot be converted, it will be set as `NaN` (due to `errors='coerce'`).\n",
    "\n",
    "2. **Calculate Cumulative Duration for Each Driver in Each Race**\n",
    "   ```python\n",
    "   pit_stops_df['cumulative_duration'] = pit_stops_df.groupby(['driverId', 'raceId'])['duration'].cumsum()\n",
    "   ```\n",
    "   - **Purpose:** Calculate the cumulative pit stop duration for each `driverId` in each race (`raceId`), showing how the total duration builds up lap by lap.\n",
    "   - **Steps:**\n",
    "     - `groupby(['driverId', 'raceId'])`: Groups the data by `driverId` and `raceId` so that the cumulative sum is computed separately for each driver in each race.\n",
    "     - `['duration'].cumsum()`: Computes the cumulative sum of pit stop durations for each group.\n",
    "\n",
    "3. **Calculate Change in Cumulative Duration Between Successive Laps**\n",
    "   ```python\n",
    "   pit_stops_df['duration_change'] = pit_stops_df.groupby(['driverId', 'raceId'])['cumulative_duration'].diff()\n",
    "   ```\n",
    "   - **Purpose:** Calculate the change in cumulative pit stop duration between successive laps for each driver.\n",
    "   - **Key Points:**\n",
    "     - `groupby(['driverId', 'raceId'])`: Groups by both `driverId` and `raceId` to calculate differences within each race and driver.\n",
    "     - `['cumulative_duration'].diff()`: Computes the difference in cumulative duration between successive laps (representing the additional time spent in each pit stop).\n",
    "\n",
    "4. **Display Relevant Data**\n",
    "   ```python\n",
    "   print(\"Pit stop analysis (total and change in duration across laps):\")\n",
    "   print(pit_stops_df[['driverId', 'raceId', 'lap', 'duration', 'cumulative_duration', 'duration_change']].tail())\n",
    "   ```\n",
    "   - **Purpose:** Display the relevant columns to understand the pit stop duration and changes over time for each driver.\n",
    "   - **Key Points:**\n",
    "     - `[['driverId', 'raceId', 'lap', 'duration', 'cumulative_duration', 'duration_change']]`: Selects only the necessary columns to display.\n",
    "     - `.tail()`: Shows the last few rows of the DataFrame to verify the results.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pit_stops_df['duration'] = pd.to_numeric(pit_stops_df['duration'], errors='coerce')\n",
    "pit_stops_df['cumulative_duration'] = pit_stops_df.groupby(['driverId', 'raceId'])['duration'].cumsum()\n",
    "pit_stops_df['duration_change'] = pit_stops_df.groupby(['driverId', 'raceId'])['cumulative_duration'].diff()\n",
    "print(\"Pit stop analysis (total and change in duration across laps):\")\n",
    "print(pit_stops_df[['driverId', 'raceId', 'lap', 'duration', 'cumulative_duration', 'duration_change']].tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. **Optimization of Fastest Lap Speed**\n",
    "\n",
    "   - **Goal**: Identify the `fastestLapSpeed` from `results_df` for each `driverId` and find the lap where they achieved it to determine the race's optimal lap.\n",
    "\n",
    "   - **Hint**\n",
    "      - Use `groupby()` to group the data by `driverId` and apply the `max()` function to isolate the fastest lap speeds.\n",
    "      - Utilize `idxmax()` to retrieve the row with the maximum lap speed for each driver.\n",
    "\n",
    "**_Solution:_** Identifying the Fastest Lap Speed for Each Driver\n",
    "\n",
    "**_Steps:_**\n",
    "\n",
    "1. **Filter Out Invalid Fastest Lap Data**\n",
    "   ```python\n",
    "   valid_results_df = results_df.dropna(subset=['fastestLapSpeed'])\n",
    "   ```\n",
    "   - **Purpose:** Remove rows where the `fastestLapSpeed` is `NaN`, as these rows do not contain valid lap speed data.\n",
    "   - **Key Points:**\n",
    "     - `dropna(subset=['fastestLapSpeed'])`: Filters out rows where `fastestLapSpeed` is missing to ensure calculations are done only on valid data.\n",
    "\n",
    "2. **Group by Driver and Identify Fastest Lap Speed**\n",
    "   ```python\n",
    "   fastest_lap = valid_results_df.groupby('driverId').apply(\n",
    "       lambda x: x.loc[x['fastestLapSpeed'].idxmax(), ['raceId', 'fastestLap', 'fastestLapSpeed']]\n",
    "   ).reset_index(drop=True)\n",
    "   ```\n",
    "   - **Purpose:** Group the dataset by `driverId` and apply a function to find the lap with the highest `fastestLapSpeed` for each driver.\n",
    "   - **Steps:**\n",
    "     - `groupby('driverId')`: Groups the data by `driverId`, ensuring the calculation is done per driver.\n",
    "     - `apply(lambda x: ...)`: For each driver, a lambda function is used to find the row with the maximum `fastestLapSpeed`.\n",
    "     - `idxmax()`: Returns the index of the row with the maximum `fastestLapSpeed`.\n",
    "     - `.loc[]`: Selects the specific row corresponding to the maximum lap speed and extracts relevant columns (`raceId`, `fastestLap`, `fastestLapSpeed`).\n",
    "   - **Result:** A DataFrame `fastest_lap` containing each driver's fastest lap details (race, lap, and speed).\n",
    "\n",
    "3. **Rename Columns for Better Readability**\n",
    "   ```python\n",
    "   fastest_lap.rename(columns={'raceId': 'Race ID', 'fastestLap': 'Fastest Lap', 'fastestLapSpeed': 'Fastest Speed'}, inplace=True)\n",
    "   ```\n",
    "   - **Purpose:** Rename the columns for improved clarity and better presentation of the final results.\n",
    "   - **Key Points:**\n",
    "     - `inplace=True`: Ensures the column renaming happens directly on the `fastest_lap` DataFrame without needing to assign it to a new variable.\n",
    "\n",
    "4. **Display the Results**\n",
    "   ```python\n",
    "   print(\"Fastest Lap Speed for Each Driver and Corresponding Lap:\")\n",
    "   print(fastest_lap)\n",
    "   ```\n",
    "   - **Purpose:** Print the final `fastest_lap` DataFrame, displaying each driver's fastest lap, the corresponding lap number, and the speed achieved.\n",
    "   - **Key Points:**\n",
    "     - `fastest_lap`: The DataFrame contains the desired results, showing which lap was the fastest and the corresponding speed for each driver.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_results_df = results_df.dropna(subset=['fastestLapSpeed'])\n",
    "fastest_lap = valid_results_df.groupby('driverId').apply(\n",
    "    lambda x: x.loc[x['fastestLapSpeed'].idxmax(), ['raceId', 'fastestLap', 'fastestLapSpeed']]\n",
    ").reset_index(drop=True)\n",
    "fastest_lap.rename(columns={'raceId': 'Race ID', 'fastestLap': 'Fastest Lap', 'fastestLapSpeed': 'Fastest Speed'}, inplace=True)\n",
    "print(\"Fastest Lap Speed for Each Driver and Corresponding Lap:\")\n",
    "print(fastest_lap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Fundamentals Exercises\n",
    "8. **Probability of a Constructor Winning**\n",
    "\n",
    "   - **Goal**: Calculate the probability of a specific `constructorId` having the highest `position` (winning) across all races in the `results_df` table.\n",
    "\n",
    "   - **Hint**\n",
    "      - Filter for rows where `positionOrder` is 1 (indicating a win), count the occurrences for each `constructorId`, and divide by the total number of races to compute the win probability.\n",
    "\n",
    "**_Solution:_** Calculating the Probability of a Constructor Winning\n",
    "\n",
    "**_Steps:_**\n",
    "\n",
    "1. **Filter for Winning Constructors**\n",
    "   ```python\n",
    "   winners_df = results_df[results_df['positionOrder'] == 1]\n",
    "   ```\n",
    "   - **Purpose:** Filter the `results_df` table to only include rows where the `positionOrder` is 1, which indicates a win.\n",
    "   - **Key Points:**\n",
    "     - `positionOrder == 1`: Selects the races where the constructor finished in first place.\n",
    "\n",
    "2. **Count the Number of Wins for Each Constructor**\n",
    "   ```python\n",
    "   win_counts = winners_df['constructorId'].value_counts()\n",
    "   ```\n",
    "   - **Purpose:** Count the number of wins for each `constructorId` by calculating the occurrences of each constructor in the filtered `winners_df` DataFrame.\n",
    "   - **Key Points:**\n",
    "     - `value_counts()`: Returns the count of unique values (constructorId) in the `winners_df`.\n",
    "\n",
    "3. **Calculate the Total Number of Races**\n",
    "   ```python\n",
    "   total_races = results_df['raceId'].nunique()\n",
    "   ```\n",
    "   - **Purpose:** Calculate the total number of unique races in the dataset.\n",
    "   - **Key Points:**\n",
    "     - `nunique()`: Counts the number of unique values in the `raceId` column, which corresponds to the total number of races.\n",
    "\n",
    "4. **Calculate the Probability of Winning for Each Constructor**\n",
    "   ```python\n",
    "   win_probabilities = (win_counts / total_races).reset_index()\n",
    "   win_probabilities.columns = ['constructorId', 'Win Probability']\n",
    "   ```\n",
    "   - **Purpose:** Calculate the probability of each constructor winning by dividing the number of wins by the total number of races.\n",
    "   - **Steps:**\n",
    "     - `win_counts / total_races`: Calculates the win probability for each constructor.\n",
    "     - `.reset_index()`: Converts the `value_counts` result into a DataFrame.\n",
    "     - Renames the columns to `constructorId` and `Win Probability`.\n",
    "\n",
    "5. **Merge Constructor Names**\n",
    "   ```python\n",
    "   win_probabilities = win_probabilities.merge(\n",
    "       constructors_df[['constructorId', 'name']],\n",
    "       on='constructorId',\n",
    "       how='left'\n",
    "   )\n",
    "   ```\n",
    "   - **Purpose:** Merge the `win_probabilities` DataFrame with the `constructors_df` to get the names of the constructors.\n",
    "   - **Key Points:**\n",
    "     - `merge()`: Merges the win probabilities with constructor names by matching `constructorId`.\n",
    "     - `how='left'`: Ensures all constructors in `win_probabilities` are kept, even if there is no match in `constructors_df`.\n",
    "\n",
    "6. **Select Relevant Columns and Rename**\n",
    "   ```python\n",
    "   win_probabilities = win_probabilities[['constructorId', 'name', 'Win Probability']]\n",
    "   win_probabilities.rename(columns={'name': 'Constructor Name'}, inplace=True)\n",
    "   ```\n",
    "   - **Purpose:** Select the relevant columns (`constructorId`, `Constructor Name`, and `Win Probability`) and rename the `name` column for better readability.\n",
    "   - **Key Points:**\n",
    "     - `rename(columns={'name': 'Constructor Name'})`: Changes the column name for clarity.\n",
    "\n",
    "7. **Display the Results**\n",
    "   ```python\n",
    "   print(\"Winning Probabilities for Each Constructor:\")\n",
    "   print(win_probabilities)\n",
    "   ```\n",
    "   - **Purpose:** Print the final `win_probabilities` DataFrame, which contains each constructor's name and their probability of winning.\n",
    "   - **Key Points:**\n",
    "     - `win_probabilities`: Displays the calculated win probabilities for each constructor.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winners_df = results_df[results_df['positionOrder'] == 1]\n",
    "win_counts = winners_df['constructorId'].value_counts()\n",
    "total_races = results_df['raceId'].nunique()\n",
    "win_probabilities = (win_counts / total_races).reset_index()\n",
    "win_probabilities.columns = ['constructorId', 'Win Probability']\n",
    "win_probabilities = win_probabilities.merge(\n",
    "    constructors_df[['constructorId', 'name']],\n",
    "    on='constructorId',\n",
    "    how='left'\n",
    ")\n",
    "win_probabilities = win_probabilities[['constructorId', 'name', 'Win Probability']]\n",
    "win_probabilities.rename(columns={'name': 'Constructor Name'}, inplace=True)\n",
    "print(\"Winning Probabilities for Each Constructor:\")\n",
    "print(win_probabilities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. **Conditional Probability of Qualifying Position**\n",
    "\n",
    "   - **Goal**: Calculate the probability that a `driverId` qualifies in the top 3 (`position` <= 3) given that they participated in qualifying, using data from `qualifying_df`.\n",
    "\n",
    "   - **Hint**\n",
    "      - Calculate the proportion of qualifying entries where the `position` is less than or equal to 3 for each driver.\n",
    "\n",
    "**_Solution:_** Calculating Conditional Probability of Qualifying in the Top 3\n",
    "\n",
    "**_Steps:_**\n",
    "\n",
    "1. **Filter Qualifying Data for Top 3 Positions**\n",
    "   ```python\n",
    "   top_3_qualifying = qualifying_df[qualifying_df['position'] <= 3]\n",
    "   ```\n",
    "   - **Purpose:** Filter the `qualifying_df` to only include entries where the driver qualified in one of the top 3 positions (`position <= 3`).\n",
    "   - **Key Points:**\n",
    "     - `position <= 3`: Selects only the rows where the driver's qualifying position is in the top 3.\n",
    "\n",
    "2. **Count the Total Number of Qualifying Entries for Each Driver**\n",
    "   ```python\n",
    "   total_qualifying_entries = qualifying_df.groupby('driverId').size()\n",
    "   ```\n",
    "   - **Purpose:** Count the total number of qualifying entries for each `driverId` (i.e., the number of races a driver participated in qualifying).\n",
    "   - **Key Points:**\n",
    "     - `groupby('driverId')`: Groups the data by `driverId` so we can count entries per driver.\n",
    "     - `size()`: Returns the number of qualifying entries per driver.\n",
    "\n",
    "3. **Count the Number of Top 3 Qualifying Entries for Each Driver**\n",
    "   ```python\n",
    "   top_3_qualifying_entries = top_3_qualifying.groupby('driverId').size()\n",
    "   ```\n",
    "   - **Purpose:** Count how many times each driver qualified in the top 3 positions.\n",
    "   - **Key Points:**\n",
    "     - This operation is performed on the filtered `top_3_qualifying` DataFrame to count the entries where the driver finished in the top 3.\n",
    "\n",
    "4. **Calculate the Probability of Qualifying in the Top 3**\n",
    "   ```python\n",
    "   qualifying_probabilities = (top_3_qualifying_entries / total_qualifying_entries).reset_index(name='Top 3 Probability')\n",
    "   ```\n",
    "   - **Purpose:** Calculate the conditional probability for each driver by dividing the number of top 3 qualifying entries by the total number of qualifying entries for that driver.\n",
    "   - **Key Points:**\n",
    "     - `top_3_qualifying_entries / total_qualifying_entries`: The fraction of top 3 finishes for each driver.\n",
    "     - `.reset_index(name='Top 3 Probability')`: Converts the result into a DataFrame with the `Top 3 Probability` column.\n",
    "\n",
    "5. **Merge with Driver Names for Readability (Optional)**\n",
    "   ```python\n",
    "   qualifying_probabilities = qualifying_probabilities.merge(\n",
    "       drivers_df[['driverId', 'forename', 'surname']],\n",
    "       on='driverId',\n",
    "       how='left'\n",
    "   )\n",
    "   ```\n",
    "   - **Purpose:** Merge the `qualifying_probabilities` DataFrame with the `drivers_df` to add the driver names (forename and surname).\n",
    "   - **Key Points:**\n",
    "     - `merge()`: Joins the two DataFrames based on `driverId` to associate the driver names with their probabilities.\n",
    "\n",
    "6. **Create Full Driver Name**\n",
    "   ```python\n",
    "   qualifying_probabilities['Driver Name'] = qualifying_probabilities['forename'] + ' ' + qualifying_probabilities['surname']\n",
    "   ```\n",
    "   - **Purpose:** Combine the `forename` and `surname` columns into a single `Driver Name` column for easier reference.\n",
    "   - **Key Points:**\n",
    "     - Concatenates the first and last names to create a full name.\n",
    "\n",
    "7. **Reorganize Columns**\n",
    "   ```python\n",
    "   qualifying_probabilities = qualifying_probabilities[['driverId', 'Driver Name', 'Top 3 Probability']]\n",
    "   ```\n",
    "   - **Purpose:** Select only the relevant columns (`driverId`, `Driver Name`, and `Top 3 Probability`) for the final output.\n",
    "\n",
    "8. **Sort by Top 3 Probability**\n",
    "   ```python\n",
    "   qualifying_probabilities_sorted = qualifying_probabilities.sort_values(by='Top 3 Probability', ascending=False)\n",
    "   ```\n",
    "   - **Purpose:** Sort the drivers based on their `Top 3 Probability` in descending order to display the drivers with the highest probabilities first.\n",
    "\n",
    "9. **Display the Results**\n",
    "   ```python\n",
    "   print(\"Top 3 Qualifying Probabilities for Each Driver (Sorted Descending):\")\n",
    "   print(qualifying_probabilities_sorted)\n",
    "   ```\n",
    "   - **Purpose:** Print the final DataFrame showing the driver names and their probabilities of qualifying in the top 3.\n",
    "   - **Key Points:**\n",
    "     - The result is sorted in descending order, making it easy to identify drivers with the highest probabilities.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3_qualifying = qualifying_df[qualifying_df['position'] <= 3]\n",
    "total_qualifying_entries = qualifying_df.groupby('driverId').size()\n",
    "top_3_qualifying_entries = top_3_qualifying.groupby('driverId').size()\n",
    "qualifying_probabilities = (top_3_qualifying_entries / total_qualifying_entries).reset_index(name='Top 3 Probability')\n",
    "qualifying_probabilities = qualifying_probabilities.merge(\n",
    "    drivers_df[['driverId', 'forename', 'surname']],\n",
    "    on='driverId',\n",
    "    how='left'\n",
    ")\n",
    "qualifying_probabilities['Driver Name'] = qualifying_probabilities['forename'] + ' ' + qualifying_probabilities['surname']\n",
    "qualifying_probabilities = qualifying_probabilities[['driverId', 'Driver Name', 'Top 3 Probability']]\n",
    "qualifying_probabilities_sorted = qualifying_probabilities.sort_values(by='Top 3 Probability', ascending=False)\n",
    "print(\"Top 3 Qualifying Probabilities for Each Driver (Sorted Descending):\")\n",
    "print(qualifying_probabilities_sorted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics Basics\n",
    "\n",
    "1. **Driver Performance Analysis:**\n",
    "\n",
    "    - **Goal:** Analyze the performance of drivers based on their race results and standings.\n",
    "\n",
    "    - **Tables Involved:** \n",
    "        - `results_df`\n",
    "        - `drivers_df`\n",
    "        - `driver_standings_df`\n",
    "\n",
    "    - **Tasks:**\n",
    "        - Find the total number of wins and podium finishes (top 3) for each driver.\n",
    "        - Calculate the average position and points across all races for each driver.\n",
    "\n",
    "**_Solution:_** Driver Performance Analysis\n",
    "\n",
    "**_Steps:_**\n",
    "\n",
    "1. **Convert 'position' column to numeric:**\n",
    "    ```python\n",
    "    results_df['position'] = pd.to_numeric(results_df['position'], errors='coerce')\n",
    "    ```\n",
    "    - **Purpose:** Convert the `position` column to a numeric format.\n",
    "    - **Explanation:** Ensures that the `position` column can be used for numerical operations like comparison (`<= 3`). Any invalid values (e.g., text) are replaced with `NaN`.\n",
    "\n",
    "2. **Calculate total wins for each driver:**\n",
    "    ```python\n",
    "    total_wins = results_df[results_df['position'] == 1].groupby('driverId').size()\n",
    "    ```\n",
    "    - **Purpose:** Find the total number of wins (1st-place finishes) for each driver.\n",
    "    - **Explanation:** Filters the rows where `position` is 1 (indicating a win) and groups the data by `driverId` to count the occurrences (number of wins).\n",
    "\n",
    "3. **Calculate podium finishes for each driver:**\n",
    "    ```python\n",
    "    podium_finishes = results_df[results_df['position'] <= 3].groupby('driverId').size()\n",
    "    ```\n",
    "    - **Purpose:** Calculate the total number of podium finishes (1st, 2nd, or 3rd) for each driver.\n",
    "    - **Explanation:** Filters for rows where `position` is less than or equal to 3 (top 3 finishes) and counts the number of podium finishes for each driver.\n",
    "\n",
    "4. **Calculate average position for each driver:**\n",
    "    ```python\n",
    "    average_position = results_df.groupby('driverId')['position'].mean()\n",
    "    ```\n",
    "    - **Purpose:** Calculate the average finishing position for each driver.\n",
    "    - **Explanation:** Groups the data by `driverId` and computes the mean position. A lower average position indicates better overall performance.\n",
    "\n",
    "5. **Calculate average points for each driver:**\n",
    "    ```python\n",
    "    average_points = results_df.groupby('driverId')['points'].mean()\n",
    "    ```\n",
    "    - **Purpose:** Calculate the average points earned by each driver.\n",
    "    - **Explanation:** Groups the data by `driverId` and computes the average number of points. Points are generally awarded based on the finishing position in a race.\n",
    "\n",
    "6. **Calculate the variance of position for each driver:**\n",
    "    ```python\n",
    "    position_variance = results_df.groupby('driverId')['position'].var()\n",
    "    ```\n",
    "    - **Purpose:** Calculate the variance of finishing positions for each driver.\n",
    "    - **Explanation:** Variance measures how consistent a driver is in their race finishes. Lower variance indicates more consistency.\n",
    "\n",
    "7. **Combine the performance metrics into a new DataFrame:**\n",
    "    ```python\n",
    "    performance_metrics = pd.DataFrame({\n",
    "        'Wins': total_wins,\n",
    "        'Podium Finishes': podium_finishes,\n",
    "        'Avg Position': average_position,\n",
    "        'Avg Points': average_points,\n",
    "        'Position Variance': position_variance\n",
    "    }).reset_index()\n",
    "    ```\n",
    "    - **Purpose:** Create a DataFrame with all the calculated performance metrics for each driver.\n",
    "    - **Explanation:** Combines all the performance metrics (wins, podium finishes, etc.) into a single DataFrame, and resets the index so that `driverId` is a column instead of the index.\n",
    "\n",
    "8. **Merge the performance metrics with driver details:**\n",
    "    ```python\n",
    "    driver_performance = performance_metrics.merge(drivers_df[['driverId', 'forename', 'surname']],\n",
    "                                                on='driverId', how='left')\n",
    "    ```\n",
    "    - **Purpose:** Merge the `performance_metrics` DataFrame with `drivers_df` to add the driver's first and last names.\n",
    "    - **Explanation:** This merge ensures that the final DataFrame contains both the driver's performance metrics and their name, based on `driverId`.\n",
    "\n",
    "9. **Display the final result:**\n",
    "    ```python\n",
    "    print(driver_performance)\n",
    "    ```\n",
    "    - **Purpose:** Display the `driver_performance` DataFrame.\n",
    "    - **Explanation:** This prints the final DataFrame, showing the performance metrics for each driver, along with their first and last names.\n",
    "\n",
    "**Result:**\n",
    "The `driver_performance` DataFrame will include the following columns:\n",
    "- **driverId**: The unique ID of each driver.\n",
    "- **Wins**: The total number of 1st-place finishes.\n",
    "- **Podium Finishes**: The total number of top 3 finishes (1st, 2nd, or 3rd).\n",
    "- **Avg Position**: The average finishing position across all races.\n",
    "- **Avg Points**: The average number of points earned by the driver.\n",
    "- **Position Variance**: The variance in the driver's finishing positions (lower is more consistent).\n",
    "- **forename**: The first name of the driver.\n",
    "- **surname**: The last name of the driver.\n",
    "\n",
    "The output will display the performance metrics for each driver.\n",
    "\n",
    "**Identifying the Most Consistent Drivers:**\n",
    "To identify the drivers with the most consistent performance (low position variance), sort the DataFrame by `Position Variance`:\n",
    "```python\n",
    "consistent_drivers = driver_performance.sort_values(by='Position Variance').reset_index(drop=True)\n",
    "print(\"Most Consistent Drivers (Low Position Variance):\")\n",
    "print(consistent_drivers)\n",
    "```\n",
    "- **Purpose:** Sorts the drivers by the variance in their finishing positions, with the most consistent drivers (low variance) appearing at the top.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['position'] = pd.to_numeric(results_df['position'], errors='coerce')\n",
    "total_wins = results_df[results_df['position'] == 1].groupby('driverId').size()\n",
    "podium_finishes = results_df[results_df['position'] <= 3].groupby('driverId').size()\n",
    "average_position = results_df.groupby('driverId')['position'].mean()\n",
    "average_points = results_df.groupby('driverId')['points'].mean()\n",
    "position_variance = results_df.groupby('driverId')['position'].var()\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Wins': total_wins,\n",
    "    'Podium Finishes': podium_finishes,\n",
    "    'Avg Position': average_position,\n",
    "    'Avg Points': average_points,\n",
    "    'Position Variance': position_variance\n",
    "}).reset_index()\n",
    "driver_performance = performance_metrics.merge(drivers_df[['driverId', 'forename', 'surname']],\n",
    "                                               on='driverId', how='left')\n",
    "\n",
    "print(driver_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 2. **Constructor Performance Over Time:**\n",
    "   - **Objective:** Compare constructor performance across different seasons.\n",
    "   - **Tables Involved:** `constructor_results_df`, `constructors_df`, `seasons_df`\n",
    "   - **Tasks:**\n",
    "     - Calculate the total points earned by each constructor in every season.\n",
    "     - Identify the constructor with the most wins across seasons.\n",
    "     - Plot the performance of top constructors over the seasons.\n",
    "\n",
    "### 3. **Fastest Lap Analysis:**\n",
    "   - **Objective:** Identify trends in fastest laps and the correlation with race results.\n",
    "   - **Tables Involved:** `results_df`, `lap_times_df`\n",
    "   - **Tasks:**\n",
    "     - Find the drivers who have the most fastest laps in races.\n",
    "     - Analyze if drivers with the fastest lap tend to finish in the top positions (correlation with `position`).\n",
    "     - Calculate the average time difference between the fastest lap and race finish time.\n",
    "\n",
    "### 4. **Pit Stop Duration and Race Results:**\n",
    "   - **Objective:** Analyze how pit stop duration affects race positions.\n",
    "   - **Tables Involved:** `pit_stops_df`, `results_df`\n",
    "   - **Tasks:**\n",
    "     - Calculate the average pit stop duration for each driver.\n",
    "     - Identify if there is a significant correlation between pit stop duration and race position.\n",
    "     - Compare the pit stop times for top finishers (position 1, 2, 3) versus lower finishers.\n",
    "\n",
    "### 5. **Qualifying and Race Performance:**\n",
    "   - **Objective:** Investigate how qualifying positions affect final race positions.\n",
    "   - **Tables Involved:** `qualifying_df`, `results_df`\n",
    "   - **Tasks:**\n",
    "     - Calculate the average qualifying position for each driver and compare it with their final race position.\n",
    "     - Analyze how much a good qualifying position improves the chances of a top finish.\n",
    "     - Identify the drivers who consistently outperform their qualifying positions.\n",
    "\n",
    "### 6. **Race Circuit Analysis:**\n",
    "   - **Objective:** Analyze how race circuits impact driver and constructor performance.\n",
    "   - **Tables Involved:** `races_df`, `circuits_df`, `results_df`\n",
    "   - **Tasks:**\n",
    "     - Group results by circuit and calculate the average race position for drivers and constructors.\n",
    "     - Identify which circuits have the most number of wins for specific drivers or constructors.\n",
    "     - Compare lap times and fastest laps at different circuits.\n",
    "\n",
    "### 7. **Driver Standings vs Constructor Standings:**\n",
    "   - **Objective:** Compare the relationship between driver standings and constructor standings.\n",
    "   - **Tables Involved:** `driver_standings_df`, `constructor_standings_df`, `drivers_df`, `constructors_df`\n",
    "   - **Tasks:**\n",
    "     - Plot the correlation between driver points and constructor points over time.\n",
    "     - Identify drivers who helped their constructors to achieve high standings.\n",
    "     - Compare the top driver and constructor rankings across multiple seasons.\n",
    "\n",
    "### 8. **Top 5 Drivers by Race Performance:**\n",
    "   - **Objective:** Identify and analyze the top-performing drivers across all races.\n",
    "   - **Tables Involved:** `results_df`, `drivers_df`\n",
    "   - **Tasks:**\n",
    "     - Rank drivers based on the number of podium finishes (top 3).\n",
    "     - Analyze the consistency of top 5 drivers (using variance in race positions).\n",
    "     - Display the performance of these top drivers in different seasons.\n",
    "\n",
    "### 9. **Race Time Analysis:**\n",
    "   - **Objective:** Compare the total race times for each race and identify trends.\n",
    "   - **Tables Involved:** `results_df`, `races_df`\n",
    "   - **Tasks:**\n",
    "     - Calculate the total race time for each race (sum of all driver times).\n",
    "     - Analyze how the total race time correlates with the race position (e.g., top finishers vs. others).\n",
    "     - Identify races with the shortest and longest total race times.\n",
    "\n",
    "### 10. **Driver Career Statistics:**\n",
    "   - **Objective:** Build career statistics for each driver across all races.\n",
    "   - **Tables Involved:** `results_df`, `drivers_df`\n",
    "   - **Tasks:**\n",
    "     - Calculate the career statistics for each driver, such as total wins, podiums, and points.\n",
    "     - Find the drivers with the longest careers in terms of race participation.\n",
    "     - Plot the career performance of a selected driver (wins, podiums, points, etc.).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
