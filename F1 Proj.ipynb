{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # F1 Data Science Project\n",
    "\n",
    " ---\n",
    "\n",
    " ## Data Science Learning Path\n",
    "\n",
    " ---\n",
    "\n",
    " ### 1. Mathematics for Data Science\n",
    "\n",
    "    - Algebra: Linear equations, matrix operations.\n",
    "\n",
    "    - Calculus: Derivatives, optimization.\n",
    "\n",
    "    - Probability fundamentals: Basic probability, conditional probability.\n",
    "\n",
    " ---\n",
    "\n",
    " ### 2. Statistics Basics\n",
    "\n",
    "    - Descriptive statistics: Mean, median, mode, standard deviation, variance.\n",
    "\n",
    "    - Probability distributions: Normal, binomial, Poisson.\n",
    "\n",
    "    - Inferential statistics: Sampling, estimation.\n",
    "\n",
    " ---\n",
    "\n",
    " ### 3. Python Programming\n",
    "\n",
    "    - Data types and structures: Lists, tuples, dictionaries, sets.\n",
    "\n",
    "    - Control structures: Loops, conditionals.\n",
    "\n",
    "    - Functions and modules.\n",
    "\n",
    "    - Data science libraries: Pandas, Numpy, Matplotlib.\n",
    "\n",
    " ---\n",
    "\n",
    " ### 4. Data Wrangling and Cleaning\n",
    "\n",
    "    - Handling missing values: Imputation, removal.\n",
    "\n",
    "    - Handling outliers: Detection and treatment.\n",
    "\n",
    "    - Data transformation: Scaling, normalization, encoding categorical variables.\n",
    "\n",
    " ---\n",
    "\n",
    " ### 5. Exploratory Data Analysis (EDA)\n",
    "\n",
    "    - Summary statistics: Mean, median, skewness, kurtosis.\n",
    "\n",
    "    - Data visualization: Histogram, boxplot, pairplot.\n",
    "\n",
    "    - Feature relationships: Correlation analysis, scatter plots.\n",
    "\n",
    " ---\n",
    "\n",
    " ### 6. Probability and Probability Distributions\n",
    "\n",
    "    - Basic probability: Rules of probability, Bayes' theorem.\n",
    "\n",
    "    - Probability distributions: Normal, binomial, Poisson, uniform distributions.\n",
    "\n",
    "    - Sampling methods: Random, stratified, cluster sampling.\n",
    "\n",
    " ---\n",
    "\n",
    " ### 7. Hypothesis Testing\n",
    "\n",
    "    - Basics: Null and alternative hypotheses.\n",
    "\n",
    "    - p-values and confidence intervals.\n",
    "\n",
    "    - Types of tests: t-tests, chi-square tests, ANOVA.\n",
    "\n",
    " ---\n",
    "\n",
    " ### 8. Data Visualization\n",
    "\n",
    "    - Basic plots: Histogram, scatter plot, line plot.\n",
    "\n",
    "    - Advanced visualizations: Heatmap, pairplot, violin plot.\n",
    "\n",
    "    - Interactive visualizations: Plotly, Dash, Tableau basics.\n",
    "\n",
    " ---\n",
    "\n",
    " ### 9. Linear Regression\n",
    "\n",
    "    - Simple linear regression.\n",
    "\n",
    "    - Multiple linear regression.\n",
    "\n",
    "    - Evaluation metrics: Mean Absolute Error (MAE), Mean Squared Error (MSE), R-squared.\n",
    "\n",
    " ---\n",
    "\n",
    " ### 10. Logistic Regression\n",
    "\n",
    " - Binary classification.\n",
    "\n",
    " - Sigmoid function and decision boundary.\n",
    "\n",
    " - Model interpretation and performance metrics.\n",
    "\n",
    " ---\n",
    "\n",
    " ### 11. Decision Trees and Random Forests\n",
    "\n",
    " - Basics of decision trees: Splitting, pruning, information gain.\n",
    "\n",
    " - Random forests: Ensemble learning, bagging.\n",
    "\n",
    " - Hyperparameters for tuning: Max depth, min samples split.\n",
    "\n",
    " ---\n",
    "\n",
    " ### 12. k-Nearest Neighbors (kNN)\n",
    "\n",
    " - Distance metrics: Euclidean, Manhattan.\n",
    "\n",
    " - Choosing k and model performance.\n",
    "\n",
    " - Applications: Classification, regression.\n",
    "\n",
    " ---\n",
    "\n",
    " ### 13. Model Evaluation Metrics\n",
    "\n",
    " - Classification metrics: Accuracy, precision, recall, F1-score, ROC-AUC.\n",
    "\n",
    " - Regression metrics: MAE, MSE, RMSE.\n",
    "\n",
    " - Cross-validation techniques.\n",
    "\n",
    " ---\n",
    "\n",
    " ### 14. Clustering Algorithms\n",
    "\n",
    " - K-means clustering: Choosing k, cluster evaluation.\n",
    "\n",
    " - Hierarchical clustering: Dendrograms, agglomerative and divisive methods.\n",
    "\n",
    " - Evaluation metrics: Silhouette score, Davies-Bouldin index.\n",
    "\n",
    " ---\n",
    "\n",
    " ### 15. Dimensionality Reduction\n",
    "\n",
    " - Principal Component Analysis (PCA): Eigenvalues, eigenvectors.\n",
    "\n",
    " - t-SNE: Visualization of high-dimensional data.\n",
    "\n",
    " - Application of dimensionality reduction in preprocessing.\n",
    "\n",
    " ---\n",
    "\n",
    " ### 16. Hyperparameter Tuning\n",
    "\n",
    " - Grid Search and Random Search.\n",
    "\n",
    " - Cross-validation: k-Fold, Leave-One-Out.\n",
    "\n",
    " - Tuning with libraries: Scikit-Learn’s GridSearchCV.\n",
    "\n",
    " ---\n",
    "\n",
    " ### 17. Neural Networks\n",
    "\n",
    " - Basics of neural networks: Perceptron, activation functions.\n",
    "\n",
    " - Backpropagation and gradient descent.\n",
    "\n",
    " - Types of layers: Input, hidden, output.\n",
    "\n",
    " ---\n",
    "\n",
    " ### 18. Deep Learning with CNNs and RNNs\n",
    "\n",
    " - Convolutional Neural Networks (CNNs): Convolutional layers, pooling.\n",
    "\n",
    " - Recurrent Neural Networks (RNNs): Sequence data, LSTM, GRU.\n",
    "\n",
    " - Applications: Image classification, natural language processing.\n",
    "\n",
    " ---\n",
    "\n",
    " ### 19. Natural Language Processing (NLP)\n",
    "\n",
    " - Text preprocessing: Tokenization, stemming, lemmatization.\n",
    "\n",
    " - Vectorization methods: Bag-of-Words, TF-IDF.\n",
    "\n",
    " - Advanced NLP: Word embeddings, language models (BERT, GPT).\n",
    "\n",
    " ---\n",
    "\n",
    " ### 20. Model Deployment and Monitoring\n",
    "\n",
    " - Model deployment: Flask, FastAPI, Docker.\n",
    "\n",
    " - Cloud platforms: AWS, GCP, Azure for model deployment.\n",
    "\n",
    " - Monitoring models: Performance tracking, retraining triggers.\n",
    "\n",
    " ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(\"Pandas version:\", pd.__version__)\n",
    "print(\"Seaborn version:\", sns.__version__)\n",
    "print(\"Matplotlib version:\", matplotlib.__version__)\n",
    "print(\"NumPy version:\", np.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Loading of Libraries.\n",
    "\n",
    "\n",
    "\n",
    " 1. **Importing Libraries:**\n",
    "\n",
    "\n",
    "\n",
    "   -   **Pandas** (`import pandas as pd`):\n",
    "\n",
    "   Pandas is like an advanced spreadsheet tool that allows us to load, manipulate, and analyze large sets of data quickly.\n",
    "\n",
    "\n",
    "\n",
    "   -   **Seaborn** (`import seaborn as sns`):\n",
    "\n",
    "   Seaborn is a tool for making nice-looking charts and graphs. It builds on top of another tool (Matplotlib) to make visualizations prettier and easier to create.\n",
    "\n",
    "\n",
    "\n",
    "   -   **Matplotlib** (`import matplotlib.pyplot as plt` and `import matplotlib`):\n",
    "\n",
    "   This is a library for creating plots and charts in Python. Think of it like drawing tools that help us visualize data.\n",
    "\n",
    "\n",
    "\n",
    "   -   **NumPy** (`import numpy as np`):\n",
    "\n",
    "   NumPy is used for handling numbers and calculations in a more efficient way. It’s great for working with large groups of numbers, especially in math-heavy tasks.\n",
    "\n",
    "\n",
    "\n",
    "   -   **Scikit-Learn** (`from sklearn.model_selection import train_test_split`):\n",
    "\n",
    "   This is a popular library for machine learning. It helps split data into training and testing parts, which is a key step in training predictive models.\n",
    "\n",
    "\n",
    "\n",
    " 2. **Setting Up Warnings:**\n",
    "\n",
    "\n",
    "\n",
    "    ```python\n",
    "\n",
    "    import warnings\n",
    "\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " 3. **Printing Version Information:**\n",
    "\n",
    "\n",
    "\n",
    "    ```python\n",
    "\n",
    "    print(\"Pandas version:\", pd.__version__)\n",
    "\n",
    "    print(\"Seaborn version:\", sns.__version__)\n",
    "\n",
    "    print(\"Matplotlib version:\", matplotlib.__version__)\n",
    "\n",
    "    print(\"NumPy version:\", np.__version__)\n",
    "\n",
    "\n",
    "\n",
    " These lines display the versions of each library in use, which helps in keeping track of the exact setup, since different versions might have small differences in functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Loading of Data.\n",
    "\n",
    "\n",
    "\n",
    " 1. **Creating a Dictionary of DataFrames**:\n",
    "\n",
    "    - A dictionary called `dataframes` is created, where each key-value pair represents a table name and its corresponding DataFrame. This setup makes it easy to iterate over multiple tables.\n",
    "\n",
    "\n",
    "\n",
    " 2. **Looping to Display Shapes and Sample Rows**:\n",
    "\n",
    "    - The first loop iterates over each DataFrame in the dictionary, printing:\n",
    "\n",
    "      - The name of the DataFrame.\n",
    "\n",
    "      - The shape of the DataFrame, which shows the number of rows and columns.\n",
    "\n",
    "      - The first few rows of data using `head()`, giving a sample preview of the data.\n",
    "\n",
    "\n",
    "\n",
    " 3. **Looping to Display Column Names**:\n",
    "\n",
    "    - The second loop iterates over each DataFrame again to print:\n",
    "\n",
    "      - The name of each table.\n",
    "\n",
    "      - A list of the column names in each DataFrame.\n",
    "\n",
    "      - This part is helpful for understanding the structure of each table and identifying available fields for analysis or further processing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Function to read CSV file from Google Drive\n",
    "def read_csv_from_drive(url):\n",
    "    try:\n",
    "        # Extract file ID and create download URL\n",
    "        file_id = url.split('/d/')[1].split('/')[0]\n",
    "        download_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "        print(f\"Downloading from: {download_url}\")\n",
    "        \n",
    "        # Download the file\n",
    "        response = requests.get(download_url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Save to temporary file\n",
    "        temp_file = 'temp_csv.csv'\n",
    "        with open(temp_file, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        \n",
    "        # Read CSV into a DataFrame\n",
    "        df = pd.read_csv(temp_file, on_bad_lines='skip')\n",
    "        os.remove(temp_file)  # Clean up temporary file\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file from {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Google Drive URLs\n",
    "urls = {\n",
    "    'circuits_df': 'https://drive.google.com/file/d/1-nmbX9yd1FWx41QouC4tM4NTtXrRF1nz/view?usp=sharing',\n",
    "    'constructor_results_df': 'https://drive.google.com/file/d/1mVRIG28qZr-z5LJci-sT3MGKgdDv3zdR/view?usp=sharing',\n",
    "    'constructor_standings_df': 'https://drive.google.com/file/d/1EbDJF5MDXOR_5igh1btuAVZJQPEYNfo0/view?usp=drive_link',\n",
    "    'lap_times_df': 'https://drive.google.com/file/d/1-UalbzTCdNOMaIvNcejKi7jcfB_9ryQZ/view?usp=drive_link',\n",
    "    'pit_stops_df': 'https://drive.google.com/file/d/1IGEHa6mbyjBlMUi84nKQf9Rufz0Gw0CV/view?usp=drive_link',\n",
    "    'qualifying_df': 'https://drive.google.com/file/d/1oJwNLCSgjnh5wyO2qibaMME6hxL-OuC2/view?usp=drive_link',\n",
    "    'results_df': 'https://drive.google.com/file/d/11vyh0O1blCuzweha8_5o60La0TJqg_rj/view?usp=drive_link',\n",
    "    'seasons_df': 'https://drive.google.com/file/d/1rtkiMn7g07ZvB8U88jFlL9P4kqw_Ud2w/view?usp=drive_link',\n",
    "    'sprint_results_df': 'https://drive.google.com/file/d/1nIZYslPrGQrFnwWboNa9ktIC7Uzcj2dR/view?usp=drive_link',\n",
    "    'status_df': 'https://drive.google.com/file/d/1L8-FZlC8OAl6QWEEGMvr8XrLUyZepkZk/view?usp=drive_link',\n",
    "    'drivers_df': 'https://drive.google.com/file/d/1fR1Y7Y1qWXZpcbpexVynH5ZewF-pBP0k/view?usp=drive_link',\n",
    "    'races_df': 'https://drive.google.com/file/d/1-IKn_OpmhhJFPLmKV-KNnVCYEFzS4vjH/view?usp=drive_link',\n",
    "    'constructors_df': 'https://drive.google.com/file/d/1umEG3vYsUi1-ilft5LRPSVXXb-J6DSUH/view?usp=drive_link',\n",
    "    'driver_standings_df': 'https://drive.google.com/file/d/1hq2zpHLsjqmUhE51guQoazAPGVQsCwbD/view?usp=drive_link'\n",
    "}\n",
    "\n",
    "# Load DataFrames\n",
    "dataframes = {name: read_csv_from_drive(url) for name, url in urls.items()}\n",
    "\n",
    "# Print DataFrame summary\n",
    "for name, df in dataframes.items():\n",
    "    if df is not None:\n",
    "        print(f\"✅ {name}: Loaded successfully.\")\n",
    "        print(f\"Shape: {df.shape}\")\n",
    "        print(f\"Columns: {list(df.columns)}\\n\")\n",
    "    else:\n",
    "        print(f\"❌ {name}: Failed to load.\\n\")\n",
    "\n",
    "# Ensure all DataFrames are loaded\n",
    "circuits_df = dataframes.get('circuits_df')\n",
    "constructor_results_df = dataframes.get('constructor_results_df')\n",
    "constructor_standings_df = dataframes.get('constructor_standings_df')\n",
    "lap_times_df = dataframes.get('lap_times_df')\n",
    "pit_stops_df = dataframes.get('pit_stops_df')\n",
    "qualifying_df = dataframes.get('qualifying_df')\n",
    "results_df = dataframes.get('results_df')\n",
    "seasons_df = dataframes.get('seasons_df')\n",
    "sprint_results_df = dataframes.get('sprint_results_df')\n",
    "status_df = dataframes.get('status_df')\n",
    "drivers_df = dataframes.get('drivers_df')\n",
    "races_df = dataframes.get('races_df')\n",
    "constructors_df = dataframes.get('constructors_df')\n",
    "driver_standings_df = dataframes.get('driver_standings_df')\n",
    "\n",
    "# Example usage of loaded DataFrames\n",
    "if circuits_df is not None:\n",
    "    unique_location_country_pairs = circuits_df[['location', 'country']].drop_duplicates()\n",
    "    print(\"Unique location-country pairs:\")\n",
    "    print(unique_location_country_pairs)\n",
    "    \n",
    "    country_circuit_count = circuits_df.groupby('country')['circuitId'].nunique().reset_index(name='circuit_count')\n",
    "    print(\"Circuit count per country:\")\n",
    "    print(country_circuit_count)\n",
    "else:\n",
    "    print(\"Failed to load circuits_df.\")\n",
    "\n",
    "# Add similar checks and usage for other DataFrames as needed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print only the successfully loaded tables\n",
    "print(\"Successfully Loaded Tables:\")\n",
    "for table_name, df in dataframes.items():\n",
    "    if df is not None:\n",
    "        print(table_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### List of tables and columns.\n",
    "\n",
    "\n",
    "\n",
    " | Table                     | Columns                                                                                                                                                                        |\n",
    "\n",
    " |---------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "\n",
    " | **circuits_df**           | `circuitId`, `circuitRef`, `name`, `location`, `country`, `lat`, `lng`, `alt`, `url`                                                                                           |\n",
    "\n",
    " | **constructor_results_df** | `constructorResultsId`, `raceId`, `constructorId`, `points`, `status`                                                                                                          |\n",
    "\n",
    " | **constructor_standings_df** | `constructorStandingsId`, `raceId`, `constructorId`, `points`, `position`, `positionText`, `wins`                                                                        |\n",
    "\n",
    " | **lap_times_df**          | `raceId`, `driverId`, `lap`, `position`, `time`, `milliseconds`                                                                                                                |\n",
    "\n",
    " | **pit_stops_df**          | `raceId`, `driverId`, `stop`, `lap`, `time`, `duration`, `milliseconds`                                                                                                        |\n",
    "\n",
    " | **qualifying_df**         | `qualifyId`, `raceId`, `driverId`, `constructorId`, `number`, `position`, `q1`, `q2`, `q3`                                                                                     |\n",
    "\n",
    " | **results_df**            | `resultId`, `raceId`, `driverId`, `constructorId`, `number`, `grid`, `position`, `positionText`, `positionOrder`, `points`, `laps`, `time`, `milliseconds`, `fastestLap`, `rank`, `fastestLapTime`, `fastestLapSpeed`, `statusId` |\n",
    "\n",
    " | **seasons_df**            | `year`, `url`                                                                                                                                                                  |\n",
    "\n",
    " | **sprint_results_df**     | `resultId`, `raceId`, `driverId`, `constructorId`, `number`, `grid`, `position`, `positionText`, `positionOrder`, `points`, `laps`, `time`, `milliseconds`, `fastestLap`, `fastestLapTime`, `statusId` |\n",
    "\n",
    " | **status_df**             | `statusId`, `status`                                                                                                                                                           |\n",
    "\n",
    " | **drivers_df**            | `driverId`, `driverRef`, `number`, `code`, `forename`, `surname`, `dob`, `nationality`, `url`                                                                                  |\n",
    "\n",
    " | **races_df**              | `raceId`, `year`, `round`, `circuitId`, `name`, `date`, `time`, `url`, `fp1_date`, `fp1_time`, `fp2_date`, `fp2_time`, `fp3_date`, `fp3_time`, `quali_date`, `quali_time`, `sprint_date`, `sprint_time` |\n",
    "\n",
    " | **constructors_df**       | `constructorId`, `constructorRef`, `name`, `nationality`, `url`                                                                                                                |\n",
    "\n",
    " | **driver_standings_df**   | `driverStandingsId`, `raceId`, `driverId`, `points`, `position`, `positionText`, `wins`                                                                                        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1. Mathematics for Data Science\n",
    "\n",
    "\n",
    "\n",
    " ### Algebra Exercises\n",
    "\n",
    " ---\n",
    "\n",
    " 1. **Filter and Analyze Circuit Locations.**\n",
    "\n",
    "    - **Goal**: Identify all unique `location` and `country` pairs in the `circuits_df` table and create a table where each `country` has a count of `circuits` it contains.\n",
    "\n",
    "    - **Hint**: Use grouping to count occurrences and display results.\n",
    "\n",
    "\n",
    "\n",
    "    **_Solution :_** Analyzing Unique Location-Country Pairs and Circuit Counts\n",
    "\n",
    "\n",
    "\n",
    "       This code looks at the `circuits_df` DataFrame to find unique locations and countries, as well as how many circuits each country has.\n",
    "\n",
    "\n",
    "\n",
    "    **_Steps :_**\n",
    "\n",
    "\n",
    "\n",
    "    1. **Find Unique Location-Country Pairs**:\n",
    "\n",
    "       - The code gets unique combinations of `location` and `country` from the `circuits_df` DataFrame. This helps us see where circuits are located without duplicates.\n",
    "\n",
    "\n",
    "\n",
    "       ```python\n",
    "\n",
    "       unique_location_country_pairs = circuits_df[['location', 'country']].drop_duplicates()\n",
    "\n",
    "\n",
    "\n",
    "    2. **Print Unique Pairs**:\n",
    "\n",
    "       - It then prints these unique location-country pairs to show the different circuits.\n",
    "\n",
    "\n",
    "\n",
    "       ```python\n",
    "\n",
    "       print(\"Unique location-country pairs:\")\n",
    "\n",
    "       print(unique_location_country_pairs)\n",
    "\n",
    "\n",
    "\n",
    "    3. **Count Circuits per Country**:\n",
    "\n",
    "       - The code groups the data by country and counts the number of unique circuits in each country. This tells us how many circuits each country has.\n",
    "\n",
    "\n",
    "\n",
    "       ```python\n",
    "\n",
    "       country_circuit_count = circuits_df.groupby('country')['circuitId'].nunique().reset_index(name='circuit_count')\n",
    "\n",
    "\n",
    "\n",
    "    4. **Print Circuit Count**:\n",
    "\n",
    "       - Finally, it prints the count of circuits for each country.\n",
    "\n",
    "\n",
    "\n",
    "       ```python\n",
    "\n",
    "       print(\"Circuit count per country:\")\n",
    "\n",
    "       print(country_circuit_count)\n",
    "\n",
    " ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# Function to read CSV file from Google Drive\n",
    "def read_csv_from_drive(url):\n",
    "    try:\n",
    "        # Extract file ID and create download URL\n",
    "        file_id = url.split('/d/')[1].split('/')[0]\n",
    "        download_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "        print(f\"Downloading from: {download_url}\")\n",
    "        \n",
    "        # Download the file\n",
    "        response = requests.get(download_url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Save to temporary file\n",
    "        temp_file = 'temp_csv.csv'\n",
    "        with open(temp_file, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        \n",
    "        # Read CSV into a DataFrame\n",
    "        df = pd.read_csv(temp_file, on_bad_lines='skip')\n",
    "        os.remove(temp_file)  # Clean up temporary file\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file from {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Google Drive URLs\n",
    "urls = {\n",
    "    'circuits_df': 'https://drive.google.com/file/d/1-nmbX9yd1FWx41QouC4tM4NTtXrRF1nz/view?usp=sharing',\n",
    "    # Add other URLs as needed\n",
    "}\n",
    "\n",
    "# Load DataFrames\n",
    "dataframes = {name: read_csv_from_drive(url) for name, url in urls.items()}\n",
    "\n",
    "# Ensure circuits_df is loaded\n",
    "circuits_df = dataframes.get('circuits_df')\n",
    "if circuits_df is not None:\n",
    "    # Your existing code\n",
    "    unique_location_country_pairs = circuits_df[['location', 'country']].drop_duplicates()\n",
    "    print(\"Unique location-country pairs:\")\n",
    "    print(unique_location_country_pairs)\n",
    "    \n",
    "    country_circuit_count = circuits_df.groupby('country')['circuitId'].nunique().reset_index(name='circuit_count')\n",
    "    print(\"Circuit count per country:\")\n",
    "    print(country_circuit_count)\n",
    "else:\n",
    "    print(\"Failed to load circuits_df.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_location_country_pairs = circuits_df[['location', 'country']].drop_duplicates()\n",
    "print(\"Unique location-country pairs:\")\n",
    "print(unique_location_country_pairs)\n",
    "country_circuit_count = circuits_df.groupby('country')['circuitId'].nunique().reset_index(name='circuit_count')\n",
    "print(\"Circuit count per country:\")\n",
    "print(country_circuit_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 2. **Matrix of Constructor Standings**\n",
    "\n",
    "    - **Goal**: Create a matrix showing the `position` of constructors across multiple `races`. Each row represents a `raceId` and each column represents a `constructorId` from the `constructor_standings_df` table.\n",
    "\n",
    "    - **Hint**: Use pivoting or matrix transformation functions to reshape data.\n",
    "\n",
    "\n",
    "\n",
    "    **_Solution:_** Creating a Constructor Position Matrix\n",
    "\n",
    "\n",
    "\n",
    "       This code builds a matrix showing the positions of constructors across multiple races. Each row represents a race (`raceId`), and each column represents a constructor (`name`).\n",
    "\n",
    "\n",
    "\n",
    "    **_Steps :_**\n",
    "\n",
    "\n",
    "\n",
    "    1. **Merge Constructor Data**:\n",
    "\n",
    "       - The `constructor_standings_df` is merged with the `constructors_df` to replace `constructorId` with the constructor's name.\n",
    "\n",
    "       - This makes the data more understandable by using names instead of numeric IDs.\n",
    "\n",
    "\n",
    "\n",
    "       ```python\n",
    "\n",
    "       merged_df = constructor_standings_df.merge(\n",
    "\n",
    "          constructors_df[['constructorId', 'name']],\n",
    "\n",
    "          on='constructorId',\n",
    "\n",
    "          how='left'\n",
    "\n",
    "       )\n",
    "\n",
    "\n",
    "\n",
    "    2. **Create the Matrix**:\n",
    "\n",
    "\n",
    "\n",
    "    - The data is pivoted into a matrix where:\n",
    "\n",
    "       - Rows (index) represent raceId (the race).\n",
    "\n",
    "       - Columns (columns) represent name (constructor name).\n",
    "\n",
    "       - Values (values) represent the position of each constructor in the respective race.\n",
    "\n",
    "\n",
    "\n",
    "       ```python\n",
    "\n",
    "       constructor_position_matrix = merged_df.pivot(\n",
    "\n",
    "          index='raceId',\n",
    "\n",
    "          columns='name',\n",
    "\n",
    "          values='position'\n",
    "\n",
    "       )\n",
    "\n",
    "\n",
    "\n",
    "    3. **Handle Missing Values**:\n",
    "\n",
    "\n",
    "\n",
    "    - Missing positions (where a constructor did not participate in a race) are filled with `\"N/A\"` for clarity.\n",
    "\n",
    "\n",
    "\n",
    "       ```python\n",
    "\n",
    "       constructor_position_matrix.fillna(\"N/A\", inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    4. **Print the Matrix**:\n",
    "\n",
    "    The final matrix is printed to display the constructor positions across races.\n",
    "\n",
    "\n",
    "\n",
    "       ```python\n",
    "\n",
    "       print(\"Constructor Position Matrix (Rows: raceId, Columns: Constructor Name):\")\n",
    "\n",
    "       print(constructor_position_matrix)\n",
    "\n",
    " ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = constructor_standings_df.merge(\n",
    "    constructors_df[['constructorId', 'name']],\n",
    "    on='constructorId',\n",
    "    how='left'\n",
    ")\n",
    "constructor_position_matrix = merged_df.pivot(\n",
    "    index='raceId',  \n",
    "    columns='name',  \n",
    "    values='position' \n",
    ")\n",
    "constructor_position_matrix.fillna(\"N/A\", inplace=True)\n",
    "print(\"Constructor Position Matrix (Rows: raceId, Columns: Constructor Name):\")\n",
    "print(constructor_position_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 3. **Sum of Points by Driver**\n",
    "\n",
    "    - **Goal**: Calculate the total `points` each driver has scored across all races using the `results_df` table.\n",
    "\n",
    "    - **Hint**: Group by `driverId` and use aggregation to sum the `points`.\n",
    "\n",
    "\n",
    "\n",
    "    **_Solution:_** Summing Points Scored by Each Driver\n",
    "\n",
    "\n",
    "\n",
    "       **_Steps :_**\n",
    "\n",
    "\n",
    "\n",
    "    1. **Merge Driver Details with Results**\n",
    "\n",
    "       ```python\n",
    "\n",
    "       merged_df = results_df.merge(drivers_df[['driverId', 'forename', 'surname']], on='driverId', how='left')\n",
    "\n",
    "       ```\n",
    "\n",
    "       - **Purpose:** Combine race results (`results_df`) with driver details (`drivers_df`) to include the driver's first and last names alongside race data.\n",
    "\n",
    "       - **Key Points:**\n",
    "\n",
    "       - `on='driverId'`: The `driverId` column is used as the key for merging the two datasets.\n",
    "\n",
    "       - `how='left'`: Ensures all rows from `results_df` are retained, even if a matching driver isn't found in `drivers_df`. Missing names will appear as `NaN`.\n",
    "\n",
    "\n",
    "\n",
    "    2. **Create a Full Driver Name**\n",
    "\n",
    "       ```python\n",
    "\n",
    "       merged_df['driver_name'] = merged_df['forename'] + ' ' + merged_df['surname']\n",
    "\n",
    "       ```\n",
    "\n",
    "       - **Purpose:** Combine the `forename` and `surname` columns into a single column, `driver_name`, for easier readability and grouping.\n",
    "\n",
    "       - **Result:** A new column, `driver_name`, is added to `merged_df`, containing the full name of each driver.\n",
    "\n",
    "\n",
    "\n",
    "    3. **Calculate Total Points by Driver**\n",
    "\n",
    "       ```python\n",
    "\n",
    "       total_driver_points = merged_df.groupby('driver_name')['points'].sum().reset_index()\n",
    "\n",
    "       ```\n",
    "\n",
    "       - **Purpose:** Group the dataset by `driver_name` and calculate the total points scored by each driver across all races.\n",
    "\n",
    "       - **Steps:**\n",
    "\n",
    "       - `groupby('driver_name')`: Groups rows by each driver's name.\n",
    "\n",
    "       - `['points'].sum()`: Sums the `points` column for each group (driver).\n",
    "\n",
    "       - `reset_index()`: Converts the grouped result back into a DataFrame for easier manipulation.\n",
    "\n",
    "\n",
    "\n",
    "    4. **Rename the Points Column**\n",
    "\n",
    "       ```python\n",
    "\n",
    "       total_driver_points.rename(columns={'points': 'total_points'}, inplace=True)\n",
    "\n",
    "       ```\n",
    "\n",
    "       - **Purpose:** Rename the `points` column in `total_driver_points` to `total_points` for clarity.\n",
    "\n",
    "       - **Key Argument:**\n",
    "\n",
    "       - `inplace=True`: Ensures the renaming happens directly on the `total_driver_points` DataFrame.\n",
    "\n",
    "\n",
    "\n",
    "    5. **Sort Drivers by Total Points**\n",
    "\n",
    "       ```python\n",
    "\n",
    "       total_driver_points = total_driver_points.sort_values(by='total_points', ascending=False)\n",
    "\n",
    "       ```\n",
    "\n",
    "       - **Purpose:** Sort the drivers in descending order of their total points.\n",
    "\n",
    "       - **Key Points:**\n",
    "\n",
    "       - `by='total_points'`: Specifies the column used for sorting.\n",
    "\n",
    "       - `ascending=False`: Ensures the drivers with the highest points appear first.\n",
    "\n",
    "\n",
    "\n",
    "    6. **Display the Results**\n",
    "\n",
    "       ```python\n",
    "\n",
    "       print(\"Total Points Scored by Each Driver:\")\n",
    "\n",
    "       print(total_driver_points)\n",
    "\n",
    "       ```\n",
    "\n",
    "       - **Purpose:** Print the final `total_driver_points` DataFrame, showing each driver's name and their total points in descending order.\n",
    "\n",
    "\n",
    "\n",
    "    ---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = results_df.merge(drivers_df[['driverId', 'forename', 'surname']], on='driverId', how='left')\n",
    "merged_df['driver_name'] = merged_df['forename'] + ' ' + merged_df['surname']\n",
    "total_driver_points = merged_df.groupby('driver_name')['points'].sum().reset_index()\n",
    "total_driver_points.rename(columns={'points': 'total_points'}, inplace=True)\n",
    "total_driver_points = total_driver_points.sort_values(by='total_points', ascending=False)\n",
    "print(\"Total Points Scored by Each Driver:\")\n",
    "print(total_driver_points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 4. **Eigenvalues of a Points Matrix**\n",
    "\n",
    "    - **Goal**: Construct a 2x2 matrix of points scored by two constructors in two races from `constructor_results_df` and compute its eigenvalues.\n",
    "\n",
    "    - **Hint**: Choose two specific `constructorId`s and `raceId`s for simplicity.\n",
    "\n",
    "\n",
    "\n",
    " **_Solution:_** Analyzing Constructor Points and Eigenvalues\n",
    "\n",
    "\n",
    "\n",
    " This code calculates a matrix of points scored by two constructors in two races and computes the eigenvalues of that matrix. It uses the `constructor_results_df` DataFrame to derive the points.\n",
    "\n",
    "\n",
    "\n",
    " **_Steps:_**\n",
    "\n",
    "\n",
    "\n",
    "    1. **Group Data by Constructor and Race**:\n",
    "\n",
    "    - The data is grouped by `constructorId` and `raceId`, and the total points scored by each constructor in each race are calculated.\n",
    "\n",
    "\n",
    "\n",
    "       ```python\n",
    "\n",
    "       selected_data = constructor_results_df.groupby(['constructorId', 'raceId'])['points'].sum().reset_index()\n",
    "\n",
    "\n",
    "\n",
    "    2. **Select Two Constructors and Two Races**:\n",
    "\n",
    "    - Two constructors and two races are chosen for simplicity and analysis.\n",
    "\n",
    "\n",
    "\n",
    "       ```python\n",
    "\n",
    "       constructors = selected_data['constructorId'].unique()[:2]\n",
    "\n",
    "       races = selected_data['raceId'].unique()[:2]\n",
    "\n",
    "\n",
    "\n",
    "    3. **Construct the Points Matrix**:\n",
    "\n",
    "\n",
    "\n",
    "    - A 2x2 matrix is created where each cell contains the points scored by a specific constructor in a specific race. If no points are available for a combination, it is set to 0.\n",
    "\n",
    "\n",
    "\n",
    "       ```python\n",
    "\n",
    "          points_matrix = np.zeros((2, 2))\n",
    "\n",
    "          for i, constructor in enumerate(constructors):\n",
    "\n",
    "             for j, race in enumerate(races):\n",
    "\n",
    "                points = selected_data[\n",
    "\n",
    "                      (selected_data['constructorId'] == constructor) &\n",
    "\n",
    "                      (selected_data['raceId'] == race)\n",
    "\n",
    "                ]['points']\n",
    "\n",
    "                points_matrix[i, j] = points.values[0] if not points.empty else 0\n",
    "\n",
    "\n",
    "\n",
    "    4. **Compute Eigenvalues**:\n",
    "\n",
    "\n",
    "\n",
    "    - The eigenvalues of the points matrix are calculated using NumPy's eigvals function. These eigenvalues provide mathematical insights into the matrix.\n",
    "\n",
    "\n",
    "\n",
    "       ```python\n",
    "\n",
    "          eigenvalues = np.linalg.eigvals(points_matrix)\n",
    "\n",
    "\n",
    "\n",
    "    5. **Print the Results**:\n",
    "\n",
    "\n",
    "\n",
    "    - The constructed points matrix and its eigenvalues are displayed.\n",
    "\n",
    "\n",
    "\n",
    "       ```python\n",
    "\n",
    "          print(\"Points Matrix:\")\n",
    "\n",
    "          print(points_matrix)\n",
    "\n",
    "          print(\"\\nEigenvalues:\")\n",
    "\n",
    "          print(eigenvalues)\n",
    "\n",
    "\n",
    "\n",
    " **_Explanation of the Output:_**\n",
    "\n",
    "\n",
    "\n",
    "    **Points Matrix**:\n",
    "\n",
    "    - The matrix represents the points scored by two constructors in two races.\n",
    "\n",
    "    - Each row is a race, and each column is a constructor.\n",
    "\n",
    "    - Example:\n",
    "\n",
    "    - Constructor 1 scored **0 points** in Race 1 and **1 point** in Race 2.\n",
    "\n",
    "    - Constructor 2 scored **0 points** in Race 1 and **4 points** in Race 2.\n",
    "\n",
    "\n",
    "\n",
    "    **Eigenvalues**:\n",
    "\n",
    "    - Eigenvalues summarize the matrix's characteristics.\n",
    "\n",
    "    - For this matrix:\n",
    "\n",
    "    - **0** means there’s no contribution from Constructor 1 in Race 1.\n",
    "\n",
    "    - **4** reflects Constructor 2’s dominant score in Race 2.\n",
    "\n",
    "\n",
    "\n",
    "    It helps quickly see which constructor performed better overall.\n",
    "\n",
    " ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = constructor_results_df.groupby(['constructorId', 'raceId'])['points'].sum().reset_index()\n",
    "constructors = selected_data['constructorId'].unique()[:2]\n",
    "races = selected_data['raceId'].unique()[:2]\n",
    "points_matrix = np.zeros((2, 2))\n",
    "for i, constructor in enumerate(constructors):\n",
    "    for j, race in enumerate(races):\n",
    "        points = selected_data[(selected_data['constructorId'] == constructor) & (selected_data['raceId'] == race)]['points']\n",
    "        points_matrix[i, j] = points.values[0] if not points.empty else 0\n",
    "eigenvalues = np.linalg.eigvals(points_matrix)\n",
    "print(\"Points Matrix:\")\n",
    "print(points_matrix)\n",
    "print(\"\\nEigenvalues:\")\n",
    "print(eigenvalues)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Calculus Exercises\n",
    "\n",
    "\n",
    "\n",
    " 5. **Rate of Change in Lap Time**\n",
    "\n",
    "\n",
    "\n",
    "    - **Goal**: Determine the rate of change in lap times for a given `driverId` by analyzing successive lap times in the `lap_times_df` table.\n",
    "\n",
    "\n",
    "\n",
    "    - **Hint**\n",
    "\n",
    "       - Use `sort_values()` to order the data by `driverId` and `lap` for proper calculation.\n",
    "\n",
    "       - Use `diff()` to compute the time difference between consecutive laps within each driver's lap records.\n",
    "\n",
    "\n",
    "\n",
    " **_Solution:_** Calculating Lap Time Change for Each Driver\n",
    "\n",
    "\n",
    "\n",
    " **_Steps:_**\n",
    "\n",
    "\n",
    "\n",
    " 1. **Sort Lap Time Data**\n",
    "\n",
    "    ```python\n",
    "\n",
    "    lap_times_df = lap_times_df.sort_values(by=['driverId', 'lap'])\n",
    "\n",
    "    ```\n",
    "\n",
    "    - **Purpose:** Ensure the data is ordered by `driverId` and `lap` so that successive laps are properly aligned for computation.\n",
    "\n",
    "    - **Key Points:**\n",
    "\n",
    "      - Sorting is crucial for the `diff()` function to work as intended.\n",
    "\n",
    "      - `by=['driverId', 'lap']`: Sorts data first by `driverId` and then by `lap` number.\n",
    "\n",
    "\n",
    "\n",
    " 2. **Calculate Rate of Change in Lap Times**\n",
    "\n",
    "    ```python\n",
    "\n",
    "    lap_times_df['lap_time_change'] = lap_times_df.groupby('driverId')['milliseconds'].diff()\n",
    "\n",
    "    ```\n",
    "\n",
    "    - **Purpose:** Compute the difference in lap times (`milliseconds`) for consecutive laps within each `driverId`.\n",
    "\n",
    "    - **Steps:**\n",
    "\n",
    "      - `groupby('driverId')`: Groups data by `driverId` so each driver's laps are processed independently.\n",
    "\n",
    "      - `['milliseconds'].diff()`: Calculates the difference in lap times between consecutive laps.\n",
    "\n",
    "    - **Result:** A new column, `lap_time_change`, is added to the DataFrame, indicating the change in lap time for each driver.\n",
    "\n",
    "\n",
    "\n",
    " 3. **Display Relevant Data**\n",
    "\n",
    "    ```python\n",
    "\n",
    "    print(\"Rate of change of lap times for each driver:\")\n",
    "\n",
    "    print(lap_times_df[['driverId', 'lap', 'milliseconds', 'lap_time_change']].tail())\n",
    "\n",
    "    ```\n",
    "\n",
    "    - **Purpose:** Display the relevant columns to understand the lap time changes for each driver.\n",
    "\n",
    "    - **Key Points:**\n",
    "\n",
    "      - `[['driverId', 'lap', 'milliseconds', 'lap_time_change']]`: Selects only the necessary columns for display.\n",
    "\n",
    "      - `.tail()`: Shows the last few rows of the DataFrame to verify results.\n",
    "\n",
    "\n",
    "\n",
    " ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lap_times_df = lap_times_df.sort_values(by=['driverId', 'lap'])\n",
    "lap_times_df['lap_time_change'] = lap_times_df.groupby('driverId')['milliseconds'].diff()\n",
    "print(\"Rate of change of lap times for each driver:\")\n",
    "print(lap_times_df[['driverId', 'lap', 'milliseconds', 'lap_time_change']].tail())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 6. **Total Pit Stop Duration Over Time**\n",
    "\n",
    "\n",
    "\n",
    "    - **Goal**: Calculate the total pit stop `duration` for a `driverId` over the course of a race, analyzing how pit stop duration changes across `laps` in `pit_stops_df`.\n",
    "\n",
    "\n",
    "\n",
    "    - **Hint**: Use the cumulative sum and analyze derivatives of cumulative times to find patterns.\n",
    "\n",
    "\n",
    "\n",
    " **_Solution:_** Calculating Total Pit Stop Duration and Changes Across Laps\n",
    "\n",
    "\n",
    "\n",
    " **_Steps:_**\n",
    "\n",
    "\n",
    "\n",
    " 1. **Convert Duration to Numeric Values**\n",
    "\n",
    "    ```python\n",
    "\n",
    "    pit_stops_df['duration'] = pd.to_numeric(pit_stops_df['duration'], errors='coerce')\n",
    "\n",
    "    ```\n",
    "\n",
    "    - **Purpose:** Ensure the `duration` column is in a numeric format to perform arithmetic operations.\n",
    "\n",
    "    - **Key Points:**\n",
    "\n",
    "      - `pd.to_numeric()`: Converts `duration` to a numeric data type. If any value cannot be converted, it will be set as `NaN` (due to `errors='coerce'`).\n",
    "\n",
    "\n",
    "\n",
    " 2. **Calculate Cumulative Duration for Each Driver in Each Race**\n",
    "\n",
    "    ```python\n",
    "\n",
    "    pit_stops_df['cumulative_duration'] = pit_stops_df.groupby(['driverId', 'raceId'])['duration'].cumsum()\n",
    "\n",
    "    ```\n",
    "\n",
    "    - **Purpose:** Calculate the cumulative pit stop duration for each `driverId` in each race (`raceId`), showing how the total duration builds up lap by lap.\n",
    "\n",
    "    - **Steps:**\n",
    "\n",
    "      - `groupby(['driverId', 'raceId'])`: Groups the data by `driverId` and `raceId` so that the cumulative sum is computed separately for each driver in each race.\n",
    "\n",
    "      - `['duration'].cumsum()`: Computes the cumulative sum of pit stop durations for each group.\n",
    "\n",
    "\n",
    "\n",
    " 3. **Calculate Change in Cumulative Duration Between Successive Laps**\n",
    "\n",
    "    ```python\n",
    "\n",
    "    pit_stops_df['duration_change'] = pit_stops_df.groupby(['driverId', 'raceId'])['cumulative_duration'].diff()\n",
    "\n",
    "    ```\n",
    "\n",
    "    - **Purpose:** Calculate the change in cumulative pit stop duration between successive laps for each driver.\n",
    "\n",
    "    - **Key Points:**\n",
    "\n",
    "      - `groupby(['driverId', 'raceId'])`: Groups by both `driverId` and `raceId` to calculate differences within each race and driver.\n",
    "\n",
    "      - `['cumulative_duration'].diff()`: Computes the difference in cumulative duration between successive laps (representing the additional time spent in each pit stop).\n",
    "\n",
    "\n",
    "\n",
    " 4. **Display Relevant Data**\n",
    "\n",
    "    ```python\n",
    "\n",
    "    print(\"Pit stop analysis (total and change in duration across laps):\")\n",
    "\n",
    "    print(pit_stops_df[['driverId', 'raceId', 'lap', 'duration', 'cumulative_duration', 'duration_change']].tail())\n",
    "\n",
    "    ```\n",
    "\n",
    "    - **Purpose:** Display the relevant columns to understand the pit stop duration and changes over time for each driver.\n",
    "\n",
    "    - **Key Points:**\n",
    "\n",
    "      - `[['driverId', 'raceId', 'lap', 'duration', 'cumulative_duration', 'duration_change']]`: Selects only the necessary columns to display.\n",
    "\n",
    "      - `.tail()`: Shows the last few rows of the DataFrame to verify the results.\n",
    "\n",
    "\n",
    "\n",
    " ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pit_stops_df['duration'] = pd.to_numeric(pit_stops_df['duration'], errors='coerce')\n",
    "pit_stops_df['cumulative_duration'] = pit_stops_df.groupby(['driverId', 'raceId'])['duration'].cumsum()\n",
    "pit_stops_df['duration_change'] = pit_stops_df.groupby(['driverId', 'raceId'])['cumulative_duration'].diff()\n",
    "print(\"Pit stop analysis (total and change in duration across laps):\")\n",
    "print(pit_stops_df[['driverId', 'raceId', 'lap', 'duration', 'cumulative_duration', 'duration_change']].tail())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 7. **Optimization of Fastest Lap Speed**\n",
    "\n",
    "\n",
    "\n",
    "    - **Goal**: Identify the `fastestLapSpeed` from `results_df` for each `driverId` and find the lap where they achieved it to determine the race's optimal lap.\n",
    "\n",
    "\n",
    "\n",
    "    - **Hint**\n",
    "\n",
    "       - Use `groupby()` to group the data by `driverId` and apply the `max()` function to isolate the fastest lap speeds.\n",
    "\n",
    "       - Utilize `idxmax()` to retrieve the row with the maximum lap speed for each driver.\n",
    "\n",
    "\n",
    "\n",
    " **_Solution:_** Identifying the Fastest Lap Speed for Each Driver\n",
    "\n",
    "\n",
    "\n",
    " **_Steps:_**\n",
    "\n",
    "\n",
    "\n",
    " 1. **Filter Out Invalid Fastest Lap Data**\n",
    "\n",
    "    ```python\n",
    "\n",
    "    valid_results_df = results_df.dropna(subset=['fastestLapSpeed'])\n",
    "\n",
    "    ```\n",
    "\n",
    "    - **Purpose:** Remove rows where the `fastestLapSpeed` is `NaN`, as these rows do not contain valid lap speed data.\n",
    "\n",
    "    - **Key Points:**\n",
    "\n",
    "      - `dropna(subset=['fastestLapSpeed'])`: Filters out rows where `fastestLapSpeed` is missing to ensure calculations are done only on valid data.\n",
    "\n",
    "\n",
    "\n",
    " 2. **Group by Driver and Identify Fastest Lap Speed**\n",
    "\n",
    "    ```python\n",
    "\n",
    "    fastest_lap = valid_results_df.groupby('driverId').apply(\n",
    "\n",
    "        lambda x: x.loc[x['fastestLapSpeed'].idxmax(), ['raceId', 'fastestLap', 'fastestLapSpeed']]\n",
    "\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    ```\n",
    "\n",
    "    - **Purpose:** Group the dataset by `driverId` and apply a function to find the lap with the highest `fastestLapSpeed` for each driver.\n",
    "\n",
    "    - **Steps:**\n",
    "\n",
    "      - `groupby('driverId')`: Groups the data by `driverId`, ensuring the calculation is done per driver.\n",
    "\n",
    "      - `apply(lambda x: ...)`: For each driver, a lambda function is used to find the row with the maximum `fastestLapSpeed`.\n",
    "\n",
    "      - `idxmax()`: Returns the index of the row with the maximum `fastestLapSpeed`.\n",
    "\n",
    "      - `.loc[]`: Selects the specific row corresponding to the maximum lap speed and extracts relevant columns (`raceId`, `fastestLap`, `fastestLapSpeed`).\n",
    "\n",
    "    - **Result:** A DataFrame `fastest_lap` containing each driver's fastest lap details (race, lap, and speed).\n",
    "\n",
    "\n",
    "\n",
    " 3. **Rename Columns for Better Readability**\n",
    "\n",
    "    ```python\n",
    "\n",
    "    fastest_lap.rename(columns={'raceId': 'Race ID', 'fastestLap': 'Fastest Lap', 'fastestLapSpeed': 'Fastest Speed'}, inplace=True)\n",
    "\n",
    "    ```\n",
    "\n",
    "    - **Purpose:** Rename the columns for improved clarity and better presentation of the final results.\n",
    "\n",
    "    - **Key Points:**\n",
    "\n",
    "      - `inplace=True`: Ensures the column renaming happens directly on the `fastest_lap` DataFrame without needing to assign it to a new variable.\n",
    "\n",
    "\n",
    "\n",
    " 4. **Display the Results**\n",
    "\n",
    "    ```python\n",
    "\n",
    "    print(\"Fastest Lap Speed for Each Driver and Corresponding Lap:\")\n",
    "\n",
    "    print(fastest_lap)\n",
    "\n",
    "    ```\n",
    "\n",
    "    - **Purpose:** Print the final `fastest_lap` DataFrame, displaying each driver's fastest lap, the corresponding lap number, and the speed achieved.\n",
    "\n",
    "    - **Key Points:**\n",
    "\n",
    "      - `fastest_lap`: The DataFrame contains the desired results, showing which lap was the fastest and the corresponding speed for each driver.\n",
    "\n",
    "\n",
    "\n",
    " ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_results_df = results_df.dropna(subset=['fastestLapSpeed'])\n",
    "fastest_lap = valid_results_df.groupby('driverId').apply(\n",
    "    lambda x: x.loc[x['fastestLapSpeed'].idxmax(), ['raceId', 'fastestLap', 'fastestLapSpeed']]\n",
    ").reset_index(drop=True)\n",
    "fastest_lap.rename(columns={'raceId': 'Race ID', 'fastestLap': 'Fastest Lap', 'fastestLapSpeed': 'Fastest Speed'}, inplace=True)\n",
    "print(\"Fastest Lap Speed for Each Driver and Corresponding Lap:\")\n",
    "print(fastest_lap)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Probability Fundamentals Exercises\n",
    "\n",
    " 8. **Probability of a Constructor Winning**\n",
    "\n",
    "\n",
    "\n",
    "    - **Goal**: Calculate the probability of a specific `constructorId` having the highest `position` (winning) across all races in the `results_df` table.\n",
    "\n",
    "\n",
    "\n",
    "    - **Hint**\n",
    "\n",
    "       - Filter for rows where `positionOrder` is 1 (indicating a win), count the occurrences for each `constructorId`, and divide by the total number of races to compute the win probability.\n",
    "\n",
    "\n",
    "\n",
    " **_Solution:_** Calculating the Probability of a Constructor Winning\n",
    "\n",
    "\n",
    "\n",
    " **_Steps:_**\n",
    "\n",
    "\n",
    "\n",
    " 1. **Filter for Winning Constructors**\n",
    "\n",
    "    ```python\n",
    "\n",
    "    winners_df = results_df[results_df['positionOrder'] == 1]\n",
    "\n",
    "    ```\n",
    "\n",
    "    - **Purpose:** Filter the `results_df` table to only include rows where the `positionOrder` is 1, which indicates a win.\n",
    "\n",
    "    - **Key Points:**\n",
    "\n",
    "      - `positionOrder == 1`: Selects the races where the constructor finished in first place.\n",
    "\n",
    "\n",
    "\n",
    " 2. **Count the Number of Wins for Each Constructor**\n",
    "\n",
    "    ```python\n",
    "\n",
    "    win_counts = winners_df['constructorId'].value_counts()\n",
    "\n",
    "    ```\n",
    "\n",
    "    - **Purpose:** Count the number of wins for each `constructorId` by calculating the occurrences of each constructor in the filtered `winners_df` DataFrame.\n",
    "\n",
    "    - **Key Points:**\n",
    "\n",
    "      - `value_counts()`: Returns the count of unique values (constructorId) in the `winners_df`.\n",
    "\n",
    "\n",
    "\n",
    " 3. **Calculate the Total Number of Races**\n",
    "\n",
    "    ```python\n",
    "\n",
    "    total_races = results_df['raceId'].nunique()\n",
    "\n",
    "    ```\n",
    "\n",
    "    - **Purpose:** Calculate the total number of unique races in the dataset.\n",
    "\n",
    "    - **Key Points:**\n",
    "\n",
    "      - `nunique()`: Counts the number of unique values in the `raceId` column, which corresponds to the total number of races.\n",
    "\n",
    "\n",
    "\n",
    " 4. **Calculate the Probability of Winning for Each Constructor**\n",
    "\n",
    "    ```python\n",
    "\n",
    "    win_probabilities = (win_counts / total_races).reset_index()\n",
    "\n",
    "    win_probabilities.columns = ['constructorId', 'Win Probability']\n",
    "\n",
    "    ```\n",
    "\n",
    "    - **Purpose:** Calculate the probability of each constructor winning by dividing the number of wins by the total number of races.\n",
    "\n",
    "    - **Steps:**\n",
    "\n",
    "      - `win_counts / total_races`: Calculates the win probability for each constructor.\n",
    "\n",
    "      - `.reset_index()`: Converts the `value_counts` result into a DataFrame.\n",
    "\n",
    "      - Renames the columns to `constructorId` and `Win Probability`.\n",
    "\n",
    "\n",
    "\n",
    " 5. **Merge Constructor Names**\n",
    "\n",
    "    ```python\n",
    "\n",
    "    win_probabilities = win_probabilities.merge(\n",
    "\n",
    "        constructors_df[['constructorId', 'name']],\n",
    "\n",
    "        on='constructorId',\n",
    "\n",
    "        how='left'\n",
    "\n",
    "    )\n",
    "\n",
    "    ```\n",
    "\n",
    "    - **Purpose:** Merge the `win_probabilities` DataFrame with the `constructors_df` to get the names of the constructors.\n",
    "\n",
    "    - **Key Points:**\n",
    "\n",
    "      - `merge()`: Merges the win probabilities with constructor names by matching `constructorId`.\n",
    "\n",
    "      - `how='left'`: Ensures all constructors in `win_probabilities` are kept, even if there is no match in `constructors_df`.\n",
    "\n",
    "\n",
    "\n",
    " 6. **Select Relevant Columns and Rename**\n",
    "\n",
    "    ```python\n",
    "\n",
    "    win_probabilities = win_probabilities[['constructorId', 'name', 'Win Probability']]\n",
    "\n",
    "    win_probabilities.rename(columns={'name': 'Constructor Name'}, inplace=True)\n",
    "\n",
    "    ```\n",
    "\n",
    "    - **Purpose:** Select the relevant columns (`constructorId`, `Constructor Name`, and `Win Probability`) and rename the `name` column for better readability.\n",
    "\n",
    "    - **Key Points:**\n",
    "\n",
    "      - `rename(columns={'name': 'Constructor Name'})`: Changes the column name for clarity.\n",
    "\n",
    "\n",
    "\n",
    " 7. **Display the Results**\n",
    "\n",
    "    ```python\n",
    "\n",
    "    print(\"Winning Probabilities for Each Constructor:\")\n",
    "\n",
    "    print(win_probabilities)\n",
    "\n",
    "    ```\n",
    "\n",
    "    - **Purpose:** Print the final `win_probabilities` DataFrame, which contains each constructor's name and their probability of winning.\n",
    "\n",
    "    - **Key Points:**\n",
    "\n",
    "      - `win_probabilities`: Displays the calculated win probabilities for each constructor.\n",
    "\n",
    "\n",
    "\n",
    " ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winners_df = results_df[results_df['positionOrder'] == 1]\n",
    "win_counts = winners_df['constructorId'].value_counts()\n",
    "total_races = results_df['raceId'].nunique()\n",
    "win_probabilities = (win_counts / total_races).reset_index()\n",
    "win_probabilities.columns = ['constructorId', 'Win Probability']\n",
    "win_probabilities = win_probabilities.merge(\n",
    "    constructors_df[['constructorId', 'name']],\n",
    "    on='constructorId',\n",
    "    how='left'\n",
    ")\n",
    "win_probabilities = win_probabilities[['constructorId', 'name', 'Win Probability']]\n",
    "win_probabilities.rename(columns={'name': 'Constructor Name'}, inplace=True)\n",
    "print(\"Winning Probabilities for Each Constructor:\")\n",
    "print(win_probabilities)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 9. **Conditional Probability of Qualifying Position**\n",
    "\n",
    "\n",
    "\n",
    "    - **Goal**: Calculate the probability that a `driverId` qualifies in the top 3 (`position` <= 3) given that they participated in qualifying, using data from `qualifying_df`.\n",
    "\n",
    "\n",
    "\n",
    "    - **Hint**\n",
    "\n",
    "       - Calculate the proportion of qualifying entries where the `position` is less than or equal to 3 for each driver.\n",
    "\n",
    "\n",
    "\n",
    " **_Solution:_** Calculating Conditional Probability of Qualifying in the Top 3\n",
    "\n",
    "\n",
    "\n",
    " **_Steps:_**\n",
    "\n",
    "\n",
    "\n",
    " 1. **Filter Qualifying Data for Top 3 Positions**\n",
    "\n",
    "    ```python\n",
    "\n",
    "    top_3_qualifying = qualifying_df[qualifying_df['position'] <= 3]\n",
    "\n",
    "    ```\n",
    "\n",
    "    - **Purpose:** Filter the `qualifying_df` to only include entries where the driver qualified in one of the top 3 positions (`position <= 3`).\n",
    "\n",
    "    - **Key Points:**\n",
    "\n",
    "      - `position <= 3`: Selects only the rows where the driver's qualifying position is in the top 3.\n",
    "\n",
    "\n",
    "\n",
    " 2. **Count the Total Number of Qualifying Entries for Each Driver**\n",
    "\n",
    "    ```python\n",
    "\n",
    "    total_qualifying_entries = qualifying_df.groupby('driverId').size()\n",
    "\n",
    "    ```\n",
    "\n",
    "    - **Purpose:** Count the total number of qualifying entries for each `driverId` (i.e., the number of races a driver participated in qualifying).\n",
    "\n",
    "    - **Key Points:**\n",
    "\n",
    "      - `groupby('driverId')`: Groups the data by `driverId` so we can count entries per driver.\n",
    "\n",
    "      - `size()`: Returns the number of qualifying entries per driver.\n",
    "\n",
    "\n",
    "\n",
    " 3. **Count the Number of Top 3 Qualifying Entries for Each Driver**\n",
    "\n",
    "    ```python\n",
    "\n",
    "    top_3_qualifying_entries = top_3_qualifying.groupby('driverId').size()\n",
    "\n",
    "    ```\n",
    "\n",
    "    - **Purpose:** Count how many times each driver qualified in the top 3 positions.\n",
    "\n",
    "    - **Key Points:**\n",
    "\n",
    "      - This operation is performed on the filtered `top_3_qualifying` DataFrame to count the entries where the driver finished in the top 3.\n",
    "\n",
    "\n",
    "\n",
    " 4. **Calculate the Probability of Qualifying in the Top 3**\n",
    "\n",
    "    ```python\n",
    "\n",
    "    qualifying_probabilities = (top_3_qualifying_entries / total_qualifying_entries).reset_index(name='Top 3 Probability')\n",
    "\n",
    "    ```\n",
    "\n",
    "    - **Purpose:** Calculate the conditional probability for each driver by dividing the number of top 3 qualifying entries by the total number of qualifying entries for that driver.\n",
    "\n",
    "    - **Key Points:**\n",
    "\n",
    "      - `top_3_qualifying_entries / total_qualifying_entries`: The fraction of top 3 finishes for each driver.\n",
    "\n",
    "      - `.reset_index(name='Top 3 Probability')`: Converts the result into a DataFrame with the `Top 3 Probability` column.\n",
    "\n",
    "\n",
    "\n",
    " 5. **Merge with Driver Names for Readability (Optional)**\n",
    "\n",
    "    ```python\n",
    "\n",
    "    qualifying_probabilities = qualifying_probabilities.merge(\n",
    "\n",
    "        drivers_df[['driverId', 'forename', 'surname']],\n",
    "\n",
    "        on='driverId',\n",
    "\n",
    "        how='left'\n",
    "\n",
    "    )\n",
    "\n",
    "    ```\n",
    "\n",
    "    - **Purpose:** Merge the `qualifying_probabilities` DataFrame with the `drivers_df` to add the driver names (forename and surname).\n",
    "\n",
    "    - **Key Points:**\n",
    "\n",
    "      - `merge()`: Joins the two DataFrames based on `driverId` to associate the driver names with their probabilities.\n",
    "\n",
    "\n",
    "\n",
    " 6. **Create Full Driver Name**\n",
    "\n",
    "    ```python\n",
    "\n",
    "    qualifying_probabilities['Driver Name'] = qualifying_probabilities['forename'] + ' ' + qualifying_probabilities['surname']\n",
    "\n",
    "    ```\n",
    "\n",
    "    - **Purpose:** Combine the `forename` and `surname` columns into a single `Driver Name` column for easier reference.\n",
    "\n",
    "    - **Key Points:**\n",
    "\n",
    "      - Concatenates the first and last names to create a full name.\n",
    "\n",
    "\n",
    "\n",
    " 7. **Reorganize Columns**\n",
    "\n",
    "    ```python\n",
    "\n",
    "    qualifying_probabilities = qualifying_probabilities[['driverId', 'Driver Name', 'Top 3 Probability']]\n",
    "\n",
    "    ```\n",
    "\n",
    "    - **Purpose:** Select only the relevant columns (`driverId`, `Driver Name`, and `Top 3 Probability`) for the final output.\n",
    "\n",
    "\n",
    "\n",
    " 8. **Sort by Top 3 Probability**\n",
    "\n",
    "    ```python\n",
    "\n",
    "    qualifying_probabilities_sorted = qualifying_probabilities.sort_values(by='Top 3 Probability', ascending=False)\n",
    "\n",
    "    ```\n",
    "\n",
    "    - **Purpose:** Sort the drivers based on their `Top 3 Probability` in descending order to display the drivers with the highest probabilities first.\n",
    "\n",
    "\n",
    "\n",
    " 9. **Display the Results**\n",
    "\n",
    "    ```python\n",
    "\n",
    "    print(\"Top 3 Qualifying Probabilities for Each Driver (Sorted Descending):\")\n",
    "\n",
    "    print(qualifying_probabilities_sorted)\n",
    "\n",
    "    ```\n",
    "\n",
    "    - **Purpose:** Print the final DataFrame showing the driver names and their probabilities of qualifying in the top 3.\n",
    "\n",
    "    - **Key Points:**\n",
    "\n",
    "      - The result is sorted in descending order, making it easy to identify drivers with the highest probabilities.\n",
    "\n",
    "\n",
    "\n",
    " ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3_qualifying = qualifying_df[qualifying_df['position'] <= 3]\n",
    "total_qualifying_entries = qualifying_df.groupby('driverId').size()\n",
    "top_3_qualifying_entries = top_3_qualifying.groupby('driverId').size()\n",
    "qualifying_probabilities = (top_3_qualifying_entries / total_qualifying_entries).reset_index(name='Top 3 Probability')\n",
    "qualifying_probabilities = qualifying_probabilities.merge(\n",
    "    drivers_df[['driverId', 'forename', 'surname']],\n",
    "    on='driverId',\n",
    "    how='left'\n",
    ")\n",
    "qualifying_probabilities['Driver Name'] = qualifying_probabilities['forename'] + ' ' + qualifying_probabilities['surname']\n",
    "qualifying_probabilities = qualifying_probabilities[['driverId', 'Driver Name', 'Top 3 Probability']]\n",
    "qualifying_probabilities_sorted = qualifying_probabilities.sort_values(by='Top 3 Probability', ascending=False)\n",
    "print(\"Top 3 Qualifying Probabilities for Each Driver (Sorted Descending):\")\n",
    "print(qualifying_probabilities_sorted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Statistics Basics\n",
    "\n",
    "\n",
    "\n",
    " 1. **Driver Performance Analysis:**\n",
    "\n",
    "\n",
    "\n",
    "     - **Goal:** Analyze the performance of drivers based on their race results and standings.\n",
    "\n",
    "\n",
    "\n",
    "     - **Tables Involved:**\n",
    "\n",
    "         - `results_df`\n",
    "\n",
    "         - `drivers_df`\n",
    "\n",
    "         - `driver_standings_df`\n",
    "\n",
    "\n",
    "\n",
    "     - **Tasks:**\n",
    "\n",
    "         - Find the total number of wins and podium finishes (top 3) for each driver.\n",
    "\n",
    "         - Calculate the average position and points across all races for each driver.\n",
    "\n",
    "\n",
    "\n",
    " **_Solution:_** Driver Performance Analysis\n",
    "\n",
    "\n",
    "\n",
    " **_Steps:_**\n",
    "\n",
    "\n",
    "\n",
    " 1. **Convert 'position' column to numeric:**\n",
    "\n",
    "     ```python\n",
    "\n",
    "     results_df['position'] = pd.to_numeric(results_df['position'], errors='coerce')\n",
    "\n",
    "     ```\n",
    "\n",
    "     - **Purpose:** Convert the `position` column to a numeric format.\n",
    "\n",
    "     - **Explanation:** Ensures that the `position` column can be used for numerical operations like comparison (`<= 3`). Any invalid values (e.g., text) are replaced with `NaN`.\n",
    "\n",
    "\n",
    "\n",
    " 2. **Calculate total wins for each driver:**\n",
    "\n",
    "     ```python\n",
    "\n",
    "     total_wins = results_df[results_df['position'] == 1].groupby('driverId').size()\n",
    "\n",
    "     ```\n",
    "\n",
    "     - **Purpose:** Find the total number of wins (1st-place finishes) for each driver.\n",
    "\n",
    "     - **Explanation:** Filters the rows where `position` is 1 (indicating a win) and groups the data by `driverId` to count the occurrences (number of wins).\n",
    "\n",
    "\n",
    "\n",
    " 3. **Calculate podium finishes for each driver:**\n",
    "\n",
    "     ```python\n",
    "\n",
    "     podium_finishes = results_df[results_df['position'] <= 3].groupby('driverId').size()\n",
    "\n",
    "     ```\n",
    "\n",
    "     - **Purpose:** Calculate the total number of podium finishes (1st, 2nd, or 3rd) for each driver.\n",
    "\n",
    "     - **Explanation:** Filters for rows where `position` is less than or equal to 3 (top 3 finishes) and counts the number of podium finishes for each driver.\n",
    "\n",
    "\n",
    "\n",
    " 4. **Calculate average position for each driver:**\n",
    "\n",
    "     ```python\n",
    "\n",
    "     average_position = results_df.groupby('driverId')['position'].mean()\n",
    "\n",
    "     ```\n",
    "\n",
    "     - **Purpose:** Calculate the average finishing position for each driver.\n",
    "\n",
    "     - **Explanation:** Groups the data by `driverId` and computes the mean position. A lower average position indicates better overall performance.\n",
    "\n",
    "\n",
    "\n",
    " 5. **Calculate average points for each driver:**\n",
    "\n",
    "     ```python\n",
    "\n",
    "     average_points = results_df.groupby('driverId')['points'].mean()\n",
    "\n",
    "     ```\n",
    "\n",
    "     - **Purpose:** Calculate the average points earned by each driver.\n",
    "\n",
    "     - **Explanation:** Groups the data by `driverId` and computes the average number of points. Points are generally awarded based on the finishing position in a race.\n",
    "\n",
    "\n",
    "\n",
    " 6. **Calculate the variance of position for each driver:**\n",
    "\n",
    "     ```python\n",
    "\n",
    "     position_variance = results_df.groupby('driverId')['position'].var()\n",
    "\n",
    "     ```\n",
    "\n",
    "     - **Purpose:** Calculate the variance of finishing positions for each driver.\n",
    "\n",
    "     - **Explanation:** Variance measures how consistent a driver is in their race finishes. Lower variance indicates more consistency.\n",
    "\n",
    "\n",
    "\n",
    " 7. **Combine the performance metrics into a new DataFrame:**\n",
    "\n",
    "     ```python\n",
    "\n",
    "     performance_metrics = pd.DataFrame({\n",
    "\n",
    "         'Wins': total_wins,\n",
    "\n",
    "         'Podium Finishes': podium_finishes,\n",
    "\n",
    "         'Avg Position': average_position,\n",
    "\n",
    "         'Avg Points': average_points,\n",
    "\n",
    "         'Position Variance': position_variance\n",
    "\n",
    "     }).reset_index()\n",
    "\n",
    "     ```\n",
    "\n",
    "     - **Purpose:** Create a DataFrame with all the calculated performance metrics for each driver.\n",
    "\n",
    "     - **Explanation:** Combines all the performance metrics (wins, podium finishes, etc.) into a single DataFrame, and resets the index so that `driverId` is a column instead of the index.\n",
    "\n",
    "\n",
    "\n",
    " 8. **Merge the performance metrics with driver details:**\n",
    "\n",
    "     ```python\n",
    "\n",
    "     driver_performance = performance_metrics.merge(drivers_df[['driverId', 'forename', 'surname']],\n",
    "\n",
    "                                                 on='driverId', how='left')\n",
    "\n",
    "     ```\n",
    "\n",
    "     - **Purpose:** Merge the `performance_metrics` DataFrame with `drivers_df` to add the driver's first and last names.\n",
    "\n",
    "     - **Explanation:** This merge ensures that the final DataFrame contains both the driver's performance metrics and their name, based on `driverId`.\n",
    "\n",
    "\n",
    "\n",
    " 9. **Display the final result:**\n",
    "\n",
    "     ```python\n",
    "\n",
    "     print(driver_performance)\n",
    "\n",
    "     ```\n",
    "\n",
    "     - **Purpose:** Display the `driver_performance` DataFrame.\n",
    "\n",
    "     - **Explanation:** This prints the final DataFrame, showing the performance metrics for each driver, along with their first and last names.\n",
    "\n",
    "\n",
    "\n",
    " **Result:**\n",
    "\n",
    " The `driver_performance` DataFrame will include the following columns:\n",
    "\n",
    " - **driverId**: The unique ID of each driver.\n",
    "\n",
    " - **Wins**: The total number of 1st-place finishes.\n",
    "\n",
    " - **Podium Finishes**: The total number of top 3 finishes (1st, 2nd, or 3rd).\n",
    "\n",
    " - **Avg Position**: The average finishing position across all races.\n",
    "\n",
    " - **Avg Points**: The average number of points earned by the driver.\n",
    "\n",
    " - **Position Variance**: The variance in the driver's finishing positions (lower is more consistent).\n",
    "\n",
    " - **forename**: The first name of the driver.\n",
    "\n",
    " - **surname**: The last name of the driver.\n",
    "\n",
    "\n",
    "\n",
    " The output will display the performance metrics for each driver.\n",
    "\n",
    "\n",
    "\n",
    " **Identifying the Most Consistent Drivers:**\n",
    "\n",
    " To identify the drivers with the most consistent performance (low position variance), sort the DataFrame by `Position Variance`:\n",
    "\n",
    " ```python\n",
    "\n",
    " consistent_drivers = driver_performance.sort_values(by='Position Variance').reset_index(drop=True)\n",
    "\n",
    " print(\"Most Consistent Drivers (Low Position Variance):\")\n",
    "\n",
    " print(consistent_drivers)\n",
    "\n",
    " ```\n",
    "\n",
    " - **Purpose:** Sorts the drivers by the variance in their finishing positions, with the most consistent drivers (low variance) appearing at the top.\n",
    "\n",
    " ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['position'] = pd.to_numeric(results_df['position'], errors='coerce')\n",
    "total_wins = results_df[results_df['position'] == 1].groupby('driverId').size()\n",
    "podium_finishes = results_df[results_df['position'] <= 3].groupby('driverId').size()\n",
    "average_position = results_df.groupby('driverId')['position'].mean()\n",
    "average_points = results_df.groupby('driverId')['points'].mean()\n",
    "position_variance = results_df.groupby('driverId')['position'].var()\n",
    "performance_metrics = pd.DataFrame({\n",
    "    'Wins': total_wins,\n",
    "    'Podium Finishes': podium_finishes,\n",
    "    'Avg Position': average_position,\n",
    "    'Avg Points': average_points,\n",
    "    'Position Variance': position_variance\n",
    "}).reset_index()\n",
    "driver_performance = performance_metrics.merge(drivers_df[['driverId', 'forename', 'surname']],\n",
    "                                               on='driverId', how='left')\n",
    "\n",
    "print(driver_performance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    " ### 2. **Constructor Performance Over Time:**\n",
    "\n",
    "    - **Objective:** Compare constructor performance across different seasons.\n",
    "\n",
    "    - **Tables Involved:** `constructor_results_df`, `constructors_df`, `seasons_df`\n",
    "\n",
    "    - **Tasks:**\n",
    "\n",
    "      - Calculate the total points earned by each constructor in every season.\n",
    "\n",
    "      - Identify the constructor with the most wins across seasons.\n",
    "\n",
    "      - Plot the performance of top constructors over the seasons.\n",
    "\n",
    "\n",
    "\n",
    " ### 3. **Fastest Lap Analysis:**\n",
    "\n",
    "    - **Objective:** Identify trends in fastest laps and the correlation with race results.\n",
    "\n",
    "    - **Tables Involved:** `results_df`, `lap_times_df`\n",
    "\n",
    "    - **Tasks:**\n",
    "\n",
    "      - Find the drivers who have the most fastest laps in races.\n",
    "\n",
    "      - Analyze if drivers with the fastest lap tend to finish in the top positions (correlation with `position`).\n",
    "\n",
    "      - Calculate the average time difference between the fastest lap and race finish time.\n",
    "\n",
    "\n",
    "\n",
    " ### 4. **Pit Stop Duration and Race Results:**\n",
    "\n",
    "    - **Objective:** Analyze how pit stop duration affects race positions.\n",
    "\n",
    "    - **Tables Involved:** `pit_stops_df`, `results_df`\n",
    "\n",
    "    - **Tasks:**\n",
    "\n",
    "      - Calculate the average pit stop duration for each driver.\n",
    "\n",
    "      - Identify if there is a significant correlation between pit stop duration and race position.\n",
    "\n",
    "      - Compare the pit stop times for top finishers (position 1, 2, 3) versus lower finishers.\n",
    "\n",
    "\n",
    "\n",
    " ### 5. **Qualifying and Race Performance:**\n",
    "\n",
    "    - **Objective:** Investigate how qualifying positions affect final race positions.\n",
    "\n",
    "    - **Tables Involved:** `qualifying_df`, `results_df`\n",
    "\n",
    "    - **Tasks:**\n",
    "\n",
    "      - Calculate the average qualifying position for each driver and compare it with their final race position.\n",
    "\n",
    "      - Analyze how much a good qualifying position improves the chances of a top finish.\n",
    "\n",
    "      - Identify the drivers who consistently outperform their qualifying positions.\n",
    "\n",
    "\n",
    "\n",
    " ### 6. **Race Circuit Analysis:**\n",
    "\n",
    "    - **Objective:** Analyze how race circuits impact driver and constructor performance.\n",
    "\n",
    "    - **Tables Involved:** `races_df`, `circuits_df`, `results_df`\n",
    "\n",
    "    - **Tasks:**\n",
    "\n",
    "      - Group results by circuit and calculate the average race position for drivers and constructors.\n",
    "\n",
    "      - Identify which circuits have the most number of wins for specific drivers or constructors.\n",
    "\n",
    "      - Compare lap times and fastest laps at different circuits.\n",
    "\n",
    "\n",
    "\n",
    " ### 7. **Driver Standings vs Constructor Standings:**\n",
    "\n",
    "    - **Objective:** Compare the relationship between driver standings and constructor standings.\n",
    "\n",
    "    - **Tables Involved:** `driver_standings_df`, `constructor_standings_df`, `drivers_df`, `constructors_df`\n",
    "\n",
    "    - **Tasks:**\n",
    "\n",
    "      - Plot the correlation between driver points and constructor points over time.\n",
    "\n",
    "      - Identify drivers who helped their constructors to achieve high standings.\n",
    "\n",
    "      - Compare the top driver and constructor rankings across multiple seasons.\n",
    "\n",
    "\n",
    "\n",
    " ### 8. **Top 5 Drivers by Race Performance:**\n",
    "\n",
    "    - **Objective:** Identify and analyze the top-performing drivers across all races.\n",
    "\n",
    "    - **Tables Involved:** `results_df`, `drivers_df`\n",
    "\n",
    "    - **Tasks:**\n",
    "\n",
    "      - Rank drivers based on the number of podium finishes (top 3).\n",
    "\n",
    "      - Analyze the consistency of top 5 drivers (using variance in race positions).\n",
    "\n",
    "      - Display the performance of these top drivers in different seasons.\n",
    "\n",
    "\n",
    "\n",
    " ### 9. **Race Time Analysis:**\n",
    "\n",
    "    - **Objective:** Compare the total race times for each race and identify trends.\n",
    "\n",
    "    - **Tables Involved:** `results_df`, `races_df`\n",
    "\n",
    "    - **Tasks:**\n",
    "\n",
    "      - Calculate the total race time for each race (sum of all driver times).\n",
    "\n",
    "      - Analyze how the total race time correlates with the race position (e.g., top finishers vs. others).\n",
    "\n",
    "      - Identify races with the shortest and longest total race times.\n",
    "\n",
    "\n",
    "\n",
    " ### 10. **Driver Career Statistics:**\n",
    "\n",
    "    - **Objective:** Build career statistics for each driver across all races.\n",
    "\n",
    "    - **Tables Involved:** `results_df`, `drivers_df`\n",
    "\n",
    "    - **Tasks:**\n",
    "\n",
    "      - Calculate the career statistics for each driver, such as total wins, podiums, and points.\n",
    "\n",
    "      - Find the drivers with the longest careers in terms of race participation.\n",
    "\n",
    "      - Plot the career performance of a selected driver (wins, podiums, points, etc.).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
